<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
	<channel>
		<title />
		<link>https://blog.jermdavis.dev/</link>
		<description />
		<copyright>2014-2022</copyright>
		<managingEditor>Jeremy Davis</managingEditor>
		<pubDate>Tue, 15 Feb 2022 08:07:53 GMT</pubDate>
		<lastBuildDate>Tue, 15 Feb 2022 08:07:53 GMT</lastBuildDate>
		<item>
			<title>Fancy paste behaviour in WPF</title>
			<link>https://blog.jermdavis.dev/posts/2022/fancy-paste-behaviour-wpf</link>
			<description>&lt;p&gt;I realised recently that I've become quite used to way many web forms let you paste image data straight into a text field. The behaviour of &amp;quot;upload the image data, and insert the correct mark-up for the image&amp;quot; is a really helpful shortcut when you're editing DevOps tickets, or Stack Overflow answers. So I started wondering how easy it would be to add that to the text editing tool I use for writing these blog posts. Turns out, not too hard, because WPF has some helpful extension patterns...&lt;/p&gt;</description>
			<author>Jeremy Davis</author>
			<guid>https://blog.jermdavis.dev/posts/2022/fancy-paste-behaviour-wpf</guid>
			<pubDate>Mon, 01 Jan 0001 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;I realised recently that I've become quite used to way many web forms let you paste image data straight into a text field. The behaviour of "upload the image data, and insert the correct mark-up for the image" is a really helpful shortcut when you're editing DevOps tickets, or Stack Overflow answers. So I started wondering how easy it would be to add that to the text editing tool I use for writing these blog posts. Turns out, not too hard, because WPF has some helpful extension patterns...&lt;!--more--&gt;&lt;/p&gt;
&lt;h2 id="the-challenge"&gt;The challenge&lt;/h2&gt;
&lt;p&gt;I'm typing this in a (very) simple WPF app I wrote. It's a basic text editor, which I've enhanced with a few helpful extras which make my writing process easier for me. I have shortcuts to insert common Markdown and HTML tags, just to save typing. It's got a "pick the right tags" dialog, which can look at my current blog posts and give me a pick list of tags I've used before. And it's able to fire up the Statiq generator to give me close-to-realtime previews of what I'm writing. The editor's code is pretty horrible right now - but it works for me.&lt;/p&gt;
&lt;p&gt;Since Markdown is plain text, the bulk of the UI is a WPF &lt;code&gt;TextBox&lt;/code&gt; that I can type into. But if you put any sort of data that isn't text onto your clipboard and try to paste it into this textbox control it won't work. The context menu option for paste will disabled and shortcut keys will do nothing. For example, if I copy an image in Paint.Net I see a greyed-out context menu:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" href="https://blog.jermdavis.dev/img/2022/01-PasteDenied.png"&gt;&lt;img alt="The context menu of a WPF textbox, with the paste option greyed out" src="https://blog.jermdavis.dev/img/2022/01-PasteDenied.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Which isn't surprising - why would a default textbox know what to do with anything that wasn't text? So the challenge is to work out how to extend this behaviour...&lt;/p&gt;
&lt;h2 id="composition-for-the-win"&gt;Composition for the win&lt;/h2&gt;
&lt;p&gt;One of the ways WPF improves upon old-style Windows Forms is that it favours a "composition before inheritance" model for adding customisations. It has a collection of extension points where you can provide composable helper objects which give new behaviour to a control. For example, in WPF we have "adorner" classes to change the way a component draws itself, rather than the old "override the &lt;code&gt;Paint()&lt;/code&gt; method that was required in Forms. Because they're composable, they are potentially reusable across multiple controls.&lt;/p&gt;
&lt;p&gt;It happens that WPF has one of these extension points for logical behaviours too - so that's the place to start implementing this behaviour.&lt;/p&gt;
&lt;h2 id="a-simple-example"&gt;A simple example&lt;/h2&gt;
&lt;p&gt;To start with this, you need to add a Nuget package to your project: &lt;code&gt;Microsoft.Xaml.Behaviours.Wpf&lt;/code&gt;. That gives you the relevant types to implement your own reusable behaviours. You start with a class for your new behaviour:&lt;/p&gt;
&lt;pre data-enlighter-language="csharp" style="width:100%; overflow:scroll;"&gt;public class PasteBehaviour : Behaviour&amp;lt;TextBox&amp;gt;
{
}
&lt;/pre&gt;
&lt;p&gt;By making the type parameter to &lt;code&gt;Behaviour&lt;/code&gt; a &lt;code&gt;TextBox&lt;/code&gt; here, we're saying that this behaviour expects to work on textboxes. But you could use more generic WPF UI types here, if your behaviour doesn't require such a specific type. And with that defined, you can attach it to any relevant UI component with some XAML. For example, on my textbox:&lt;/p&gt;
&lt;pre data-enlighter-language="xml" style="width:100%; overflow:scroll;"&gt;&amp;lt;TextBox&amp;gt;
    &amp;lt;behaviour:Interaction.Behaviors&amp;gt;
        &amp;lt;local:PasteBehavior/&amp;gt;
    &amp;lt;/behaviour:Interaction.Behaviors&amp;gt;
&amp;lt;/TextBox&amp;gt;
&lt;/pre&gt;
&lt;p&gt;Here the &lt;code&gt;behaviour&lt;/code&gt; namespace maps to that Nuget package's namespace: &lt;code&gt;http://schemas.microsoft.com/xaml/behaviors&lt;/code&gt; and &lt;code&gt;local&lt;/code&gt; is the namespace for where the custom behaviour class is declared.&lt;/p&gt;
&lt;p&gt;To make this type do custom pasting behaviour, it needs two key things. First is logic to attach and detach the its code from the UI element. And the second is the logic for whatever the new behaviour should actually do.&lt;/p&gt;
&lt;p&gt;Attaching and detaching are pretty simple - there methods to overload in your behaviour. In those, you can attach and detach whatever event handlers you need:&lt;/p&gt;
&lt;pre data-enlighter-language="csharp" style="width:100%; overflow:scroll;"&gt;protected override void OnAttached()
{
    base.OnAttached();

    CommandManager.AddPreviewExecutedHandler(AssociatedObject, onPreviewExecuted);
    CommandManager.AddPreviewCanExecuteHandler(AssociatedObject, onPreviewCanExecute);
}

protected override void OnDetaching()
{
    base.OnDetaching();

    CommandManager.RemovePreviewExecutedHandler(AssociatedObject, onPreviewExecuted);
    CommandManager.RemovePreviewCanExecuteHandler(AssociatedObject, onPreviewCanExecute);
}
&lt;/pre&gt;
&lt;p&gt;In this case, the key events to handle are ones that preview the "can execute" and "executed" events for some routed commands. A routed command is the way WPF binds actions like "button clicked" or "shortcut key pressed" to UI elements. So by previewing these we can spot pasting behaviour however it's triggered, and apply our custom logic. The &lt;code&gt;AssociatedObject&lt;/code&gt; here is whatever &lt;code&gt;TextBox&lt;/code&gt; this &lt;code&gt;Behaviour&amp;lt;&amp;gt;&lt;/code&gt; class has been bound to.&lt;/p&gt;
&lt;p&gt;The logic for previewing the "can execute" event is fairly simple. If the command being previewed is "Paste" we need to override the logic for "can this control accept the clipboard data format that's present" and allow it to accept image data. (The default control we're extending will already handle text here) We can do that with something like:&lt;/p&gt;
&lt;pre data-enlighter-language="csharp" style="width:100%; overflow:scroll;"&gt;private void onPreviewCanExecute(object sender, CanExecuteRoutedEventArgs e)
{
    if (e.Command == ApplicationCommands.Paste)
    {
        e.CanExecute = Clipboard.ContainsImage();
        e.Handled = Clipboard.ContainsImage();
    }
}
&lt;/pre&gt;
&lt;p&gt;By setting the value of &lt;code&gt;CanExecute&lt;/code&gt; we're extending this "can the control accept the data" logic. And by setting &lt;code&gt;Handled&lt;/code&gt; we tell the runtime that we made a change. And with that in place, we should see that the context menu "paste" entry our textbox will not be greyed out if we have bitmap data on the clipboard.&lt;/p&gt;
&lt;p&gt;Next the code needs to extend the actual "data is being pasted" event - which the attachment logic above is sending to a &lt;code&gt;onPreviewExecuted&lt;/code&gt; method in this behaviour object. As before, that needs to check that the command being processed is "paste" and that the clipboard data is an image. But if those tests pass, it can get on and perform its custom functions, before again setting &lt;code&gt;Handled&lt;/code&gt; true to show it did stuff with the event. And as noted above, the &lt;code&gt;AssociatedObject&lt;/code&gt; here (whatever we've bound this behaviour logic too) is a &lt;code&gt;TextBox&lt;/code&gt; so we can do operations on the text it contains:&lt;/p&gt;
&lt;pre data-enlighter-language="csharp" style="width:100%; overflow:scroll;"&gt;private void onPreviewExecuted(object sender, ExecutedRoutedEventArgs e)
{
    if (e.Command == ApplicationCommands.Paste)
    {
        if (Clipboard.ContainsImage())
        {
            // work out a disk filename and web url for our new image
            // save the image to disk

            var markup = $"![Alt text here](/web-path-to-file/goes-here.png)";

            AssociatedObject.Text = AssociatedObject.Text.Insert(AssociatedObject.SelectionStart, markup);

            e.Handled = true;
        }
    }
}
&lt;/pre&gt;
&lt;p&gt;So the outcome of all of this is that the custom code written above "previews" the events sent to the textbox. We get to run the extra code before the default behaviour of the textbox runs, and hence we can extend its features. So now when I copy some image data from Paint.Net, I see this:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" href="https://blog.jermdavis.dev/img/2022/01-PasteAllowed.png"&gt;&lt;img alt="The context menu of a WPF textbox, with the paste option enabled" src="https://blog.jermdavis.dev/img/2022/01-PasteAllowed.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And if I click "Paste" or hit &lt;code&gt;Ctrl-V&lt;/code&gt; I now get my link inserted:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" href="https://blog.jermdavis.dev/img/2022/01-PasteCompleted.png"&gt;&lt;img alt="" src="https://blog.jermdavis.dev/img/2022/01-PasteCompleted.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I've skipped how the clipboard data ends up as an image file with a URL here. But that's not really relevant to the basic pattern for extending paste behaviour. (And saving images is fairly easily googleable) And what's above is pretty much all the code required to allow doing this a data conversion to paste something that's not text into a texbox.&lt;/p&gt;
&lt;p&gt;If you'd like to fiddle with this yourself, there's a &lt;a target="_blank" href="https://blog.jermdavis.dev/files/PasteBehavior.zip"&gt;zip of the basic code above you can grab if you want&lt;/a&gt;...&lt;/p&gt;
</content:encoded>
			<comments xmlns="http://purl.org/rss/1.0/modules/slash/">0</comments>
		</item>
		<item>
			<title>Docker without the desktop</title>
			<link>https://blog.jermdavis.dev/posts/2022/docker-without-desktop</link>
			<description>&lt;p&gt;If you're reading this soon after I post it then it's very nearly the end of the &amp;quot;grace period&amp;quot; where anyone can run Docker Desktop. As of 1st February &lt;a href="https://www.docker.com/pricing/faq#:~:text=Do%20I%20need%20to%20pay%20to%20continue%20to%20use%20Docker%20Desktop%3F" target="_blank" rel="noopener"&gt;if your business meets certain requirements you have to pay for each user&lt;/a&gt;. So what can us Sitecore devs do if we aren't in a position to pay that fee? Well the good news is you can run Docker without the Desktop bit, and it's not too tricky once you wrap your head around a few things...&lt;/p&gt;</description>
			<author>Jeremy Davis</author>
			<guid>https://blog.jermdavis.dev/posts/2022/docker-without-desktop</guid>
			<pubDate>Tue, 01 Feb 2022 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;If you're reading this soon after I post it then it's very nearly the end of the "grace period" where anyone can run Docker Desktop. As of 1st February &lt;a href="https://www.docker.com/pricing/faq#:~:text=Do%20I%20need%20to%20pay%20to%20continue%20to%20use%20Docker%20Desktop%3F" target="_blank" rel="noopener"&gt;if your business meets certain requirements you have to pay for each user&lt;/a&gt;. So what can us Sitecore devs do if we aren't in a position to pay that fee? Well the good news is you can run Docker without the Desktop bit, and it's not too tricky once you wrap your head around a few things...&lt;!--more--&gt;&lt;/p&gt;
&lt;p&gt;I should note that I've been working this out on Windows 10 Professional. It's possible that this needs tweaking for Windows 11, but I've only had the chance to test the steps against Win 10 VMs in Azure as that's my use case.&lt;/p&gt;
&lt;h2 id="first-prerequisites"&gt;First: Prerequisites&lt;/h2&gt;
&lt;p&gt;Microsoft provide two optional features for Windows which are needed for Docker to run. One is the Hyper-V virtualisation infrastructure that allows the Docker engine to run VMs, and the other is Microsoft's containers feature.&lt;/p&gt;
&lt;p&gt;It's easy to verify and install optional features via PowerShell. You can call &lt;code&gt;Get-WindowsOptionalFeature&lt;/code&gt; to test if a feature has been installed, and &lt;code&gt;Enable-WindowsOptionalFeature&lt;/code&gt; if you need to add it. So I tried wrapping those up in a helper function to install a named feature:&lt;/p&gt;
&lt;pre data-enlighter-language="powershell" style="width:100%; overflow:scroll;"&gt;function VerifyWindowsFeature
{
	param(
		[string]$featureName
	)
	
	$hasFeature = (Get-WindowsOptionalFeature -FeatureName $featureName -Online | Select -ExpandProperty State) -eq "Enabled"
	if(-not $hasFeature)
	{
		Write-Host "$featureName feature not currently installed - adding" -ForegroundColor Yellow
		$result = Enable-WindowsOptionalFeature -Online -FeatureName $featureName -NoRestart -All

		return $result.RestartNeeded
	}
	else
	{
		Write-Host "$featureName feature is already installed" -ForegroundColor Green
		return $false
	}
}
&lt;/pre&gt;
&lt;p&gt;Installing features like this often requires a restart - but helpfully you can tell Windows "don't reboot please" and get a flag back saying whether a reboot is required. So this function can be called a couple of times to install the two features needed, and then we can test if a reboot is required:&lt;/p&gt;
&lt;pre data-enlighter-language="powershell" style="width:100%; overflow:scroll;"&gt;function EnsureWindowsFeatures
{
	$containersNeedsRestart = VerifyWindowsFeature "Containers"
	$hyperVNeedsReboot = VerifyWindowsFeature "Microsoft-Hyper-V"

	if($containersNeedsRestart -or $hyperVNeedsReboot)
	{
		throw "Restart required after adding Windows features"
	}
}
&lt;/pre&gt;
&lt;p&gt;I toyed with the idea of using &lt;code&gt;Restart-Computer&lt;/code&gt; here to force a reboot, but ended up leaving it out. I'm not sure that's the best idea. But after this has run and a reboot has been performed (if needed) the machine should be in a state to install Docker.&lt;/p&gt;
&lt;h2 id="second-the-docker-engine"&gt;Second: The Docker Engine&lt;/h2&gt;
&lt;p&gt;It's not well advertised, but Docker does provide a simple download for just the Windows container engine. I found this via &lt;a href="https://lippertmarkus.com/2021/09/04/containers-without-docker-desktop/" target="_blank" rel="noopener"&gt;a helpful blog post&lt;/a&gt;, which has a very basic script for installing the Docker engine. It's interesting to note that this download is specifically for Windows containers though - unlike the Docker Desktop install, it doesn't appear to support switching over to run Linux images. The post does highlight what you need to do in order to run in mixed-mode though, if you want to investigate that - but I was focused on Windows containers for this, so I've stuck with the simplest solution.&lt;/p&gt;
&lt;p&gt;That blog post gave the basic outline for getting the Docker engine to run: Download and extract the zip file, add its location to the system path, and register the Docker service. But the script in the blog post doesn't deal with the idea that you might want to change versions, or address the issue of running containers when you're not an admin. So a bit of rework was in order for my needs, and I got to experimenting...&lt;/p&gt;
&lt;p&gt;The first thing I wanted to check was whether the Docker service was already running. That's fairly easy to do with PowerShell - you can filter the results of &lt;code&gt;Get-Service&lt;/code&gt; by the known name of the Docker service that gets installed. If there are results then the service exists. The result is an object which gives you the name and state of that service, so you can tell if it's running or not. And if it is you can check if there are any active containers. I probably need a better way to handle this, but for a first pass the script throws an exception at that point - I didn't want to try and delete the service if it was working. But otherwise the service can be stopped and (since we know at this point that the Docker code must already be present) the command line to unregister it can be called:&lt;/p&gt;
&lt;pre data-enlighter-language="powershell" style="width:100%; overflow:scroll;"&gt;function StopAndRemoveExistingService
{
    param(
        [string]$svcName
    )
    $service = Get-Service | where { $_.Name -eq $svcName }
    if($service.length -eq 0)
    {
        Write-Host "No existing service for $svcName" -ForegroundColor Green
    }
    else
    {
        $service | % {
          Write-Host "Service '$($_.DisplayName)' exists" -ForegroundColor Yellow
          if($_.Status -eq "Running")
          {
            Write-Host "$($_.Name) service is running" -ForegroundColor Yellow

            $items = docker ps -q

            if($items -ne $null)
            {
                throw "Containers are running - stop them before running this script"
            }
          }

          Write-Host "Removing service" -ForegroundColor Green
          Stop-Service $_.Name
          dockerd --unregister-service
        }
    }
}
&lt;/pre&gt;
&lt;p&gt;So with the service stopped and unregistered (if it existed) the next job is to download the archive that Docker provide. Given I was running this code fairly often while I tested, I optimised it a bit by avoiding the download if the file already existed. The &lt;code&gt;$name&lt;/code&gt; variable here is just to make the debug output more readable, as I figured this function might be useful for more than one download in this bit of work: (Spoiler - it was...)&lt;/p&gt;
&lt;pre data-enlighter-language="powershell" style="width:100%; overflow:scroll;"&gt;function DownloadFile
{
    param(
        [string]$name,
        [string]$downloadUrl,
        [string]$output
    )

    if(-not(Test-Path $output))
    {
        Write-Host "Downloading $name file" -ForegroundColor Green
        Invoke-WebRequest -Uri $downloadUrl -OutFile $output
    }
    else
    {
        Write-Host "$name already exists" -ForegroundColor Yellow
    }
}
&lt;/pre&gt;
&lt;p&gt;Working out the newest &lt;code&gt;$downloadUrl&lt;/code&gt; here (for the latest version of Docker) is a project for another day - but for the moment it's easy enough to call this function with a fixed version string like &lt;code&gt;https://download.docker.com/win/static/stable/x86_64/docker-20.10.8.zip&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;With that zip downloaded, it can be extracted easily enough:&lt;/p&gt;
&lt;pre data-enlighter-language="powershell" style="width:100%; overflow:scroll;"&gt;Expand-Archive $dockerZip -DestinationPath $dockerEnginePath -Force
&lt;/pre&gt;
&lt;p&gt;In order to be able to run the "register Docker as a service" command, the code needs to make sure that the folder which has been unzipped is in the system path. The easiest way to handle that is to check if the install folder is already in the path, and if not add it:&lt;/p&gt;
&lt;pre data-enlighter-language="powershell" style="width:100%; overflow:scroll;"&gt;function EnsureDockerInPath
{
    param(
        [string]$installPath
    )

    $path = [System.Environment]::GetEnvironmentVariable("Path","Machine")
    if(-not($path.Contains($installPath)))
    {
        $newPath = "$($env:path);$($installPath)"
        Write-Host "New path: $newPath" -ForegroundColor Green
        [Environment]::SetEnvironmentVariable("Path", $newPath, [System.EnvironmentVariableTarget]::Machine)
        $env:Path = [System.Environment]::GetEnvironmentVariable("Path","Machine") + ";" + [System.Environment]::GetEnvironmentVariable("Path","User")
    }
    else
    {
        Write-Host "Path is already correct" -ForegroundColor Yellow
    }
}
&lt;/pre&gt;
&lt;p&gt;I suspect this isn't "right" as there are circumstances where the test might get the wrong answer, but it's good enough for a first pass.&lt;/p&gt;
&lt;p&gt;And with that done, it's easy to install and start the service:&lt;/p&gt;
&lt;pre data-enlighter-language="powershell" style="width:100%; overflow:scroll;"&gt;function EnsureDockerServiceRunning
{
    param(
        [string]$svcName
    )
	
    Write-Host "Registering &amp;amp; starting $svcName service" -ForegroundColor Green
    dockerd --register-service
    Start-Service $svcName
}
&lt;/pre&gt;
&lt;p&gt;Those functions are enough to get a basic install running. They can be combined together into a simple overall script:&lt;/p&gt;
&lt;pre data-enlighter-language="powershell" style="width:100%; overflow:scroll;"&gt;#Requires -RunAsAdministrator
param(
    [string]$dockerEnginePath = "C:\",
    [string]$dockerInstallPath = "C:\Docker",
    [string]$dockerEngineUrl = "https://download.docker.com/win/static/stable/x86_64/docker-20.10.8.zip",
    [string]$dockerZip = "docker.zip",

    [string]$serviceName = "docker",
)

# Make sure Hyper-V etc is installed
EnsureWindowsFeatures

# Go to this user's downloads folder
pushd $(New-Object -ComObject Shell.Application).NameSpace('shell:Downloads').Self.Path

# stop &amp;amp; remove any running service if possible
StopAndRemoveExistingService $serviceName

# Fetch the docker engine and unzip it
DownloadFile "Docker" $dockerEngineUrl $dockerZip
Expand-Archive $dockerZip -DestinationPath $dockerEnginePath -Force
Remove-Item $dockerZip

# Make sure the docker folder is in the path
EnsureDockerInPath $dockerInstallPath

# Get docker service running
EnsureDockerServiceRunning $serviceName

popd
&lt;/pre&gt;
&lt;p&gt;After running that script and dealing with any reboots required you should be able to run a simple test container:&lt;/p&gt;
&lt;pre data-enlighter-language="powershell" style="width:100%; overflow:scroll;"&gt;docker run hello-world
&lt;/pre&gt;
&lt;p&gt;But, you won't be able to run Sitecore yet...&lt;/p&gt;
&lt;h2 id="third-docker-compose"&gt;Third: Docker Compose&lt;/h2&gt;
&lt;p&gt;The current versions of the Docker engine include Docker Compose as a built-in command - but they have v2 built in to the command line tools. The Docker &lt;a href="https://github.com/sitecore/docker-examples" target="_blank" rel="noopener"&gt;Compose files provided by Sitecore for running developer instances&lt;/a&gt; require v1 at present, however. If you try to start these examples from the command line after running the install outlined above, you'd have to be running &lt;code&gt;docker compose up&lt;/code&gt;. Note the use of a space rather than a hyphen here. That's &lt;code&gt;docker compose&lt;/code&gt; rather than &lt;code&gt;docker-compose&lt;/code&gt; - a subtlety that tripped me up quite hard. The hyphened variant will give a "command not found" error at this point.&lt;/p&gt;
&lt;p&gt;But running the version with the space also gets an error:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" href="https://blog.jermdavis.dev/img/2022/01-IncorrectComposeVersion.png"&gt;&lt;img alt="A console showing an error message caused by the incorrect docker-compose version" src="https://blog.jermdavis.dev/img/2022/01-IncorrectComposeVersion.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For Google's benefit, the important part of that message is:&lt;/p&gt;
&lt;pre data-enlighter-theme="droide-text" data-enlighter-language="text" style="width:100%; overflow:scroll;"&gt;Error response from daemon: 
Unrecognised volume spec: file '\\.\pipe\docker_engine` cannot be mapped. 
Only directories can be mapped on this platform.
&lt;/pre&gt;
&lt;p&gt;That looks like something tricky, but it's actually just this versioning issue. When you're running Docker Desktop there's a config setting for "stick with Compose V1", and that distratcted me for a while trying to find the option for doing this with the simple version that has been downloaded here. But that's entirely the wrong approach, it turns out. You're stuck with V2 for the built-in version here, but you can separately download a V1 release of the "docker-compose" command and use that instead.&lt;/p&gt;
&lt;p&gt;The code for the separate &lt;code&gt;docker-compose&lt;/code&gt; command lives on GitHub, and you can find assorted versions &lt;a href="https://github.com/docker/compose/releases/" target="_blank" rel="noopener"&gt;in the releases there&lt;/a&gt;. So to get something that's compatible with the files we're working with, we need to take the most recent V1 release. There's no installation required here. The download is a plain &lt;code&gt;.exe&lt;/code&gt; file which can be copied to the Docker folder we created above, and run as-is.&lt;/p&gt;
&lt;p&gt;The extra code to cope with that is fairly simple, and can be added into the base script above. It needs a couple of extra parameters to the overall script:&lt;/p&gt;
&lt;pre data-enlighter-language="powershell" style="width:100%; overflow:scroll;"&gt;param(
    [string]$composeEngineUrl = "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-Windows-x86_64.exe",
    [string]$composeExe = "docker-compose.exe"
)
&lt;/pre&gt;
&lt;p&gt;And the download operation can be added to the script's logic&lt;/p&gt;
&lt;pre data-enlighter-highlight="&amp;quot;4-6&amp;quot;" data-enlighter-language="powershell" style="width:100%; overflow:scroll;"&gt;# Get docker service running
EnsureDockerServiceRunning $serviceName

DownloadFile "Compose" $composeEngineUrl $composeExe
Unblock-File $composeExe
Move-Item $composeExe $dockerInstallPath

popd
&lt;/pre&gt;
&lt;p&gt;Adding that onto the basic script allows you to run an install which will be able to start an instance of Sitecore.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://blog.jermdavis.dev/img/2022/01-SuccessfulVersion.png"&gt;&lt;img alt="Installs script allowing 'docker version' to run" src="https://blog.jermdavis.dev/img/2022/01-SuccessfulVersion.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(Note, if the path to Docker is added by this script, you may well need to open a new PowerShell window in order to run Docker. I thought I'd done the business necessary to refresh the session path, but it doesn't always work for me. Another issue to look into later. But starting a new PowerShell session does always seem to get the new path so the workaround is simple enough for the moment)&lt;/p&gt;
&lt;h2 id="fourth-non-admin-users"&gt;Fourth: Non-admin users&lt;/h2&gt;
&lt;p&gt;One thing that took me a while to work out was that the default installation only seems to work if you're running docker commands from an elevated console window. Users who don't have "adminsitrator" rights will get an error message that the Docker CLI commands can't access the named pipe used to talk to the engine even though the service is up and running.&lt;/p&gt;
&lt;p&gt;That could be an issue for some users, so I did a bit more digging into how this might be resolved. I came across some google results explaining that you need to &lt;a href="https://github.com/tfenster/dockeraccesshelper" target="_blank" rel="noopener"&gt;explicity grant rights to non-admin&lt;/a&gt; users to allow them access to the Docker service. I didn't want to have an external dependency for this bit of script, so I pulled in the core behaviour there to a function:&lt;/p&gt;
&lt;pre data-enlighter-language="powershell" style="width:100%; overflow:scroll;"&gt;function GrantRights
{
    param(
        $domain,
        $user
    )

    $account="$($domain)\$($user)"
    $npipe = "\\.\pipe\docker_engine"                                                                                 
    $dInfo = New-Object "System.IO.DirectoryInfo" -ArgumentList $npipe                                               
    $dSec = $dInfo.GetAccessControl()                                                                                 
    $fullControl =[System.Security.AccessControl.FileSystemRights]::FullControl                                       
    $allow =[System.Security.AccessControl.AccessControlType]::Allow                                                  
    $rule = New-Object "System.Security.AccessControl.FileSystemAccessRule" -ArgumentList $account,$fullControl,$allow
    $dSec.AddAccessRule($rule)                                                                                        
    $dInfo.SetAccessControl($dSec)
}
&lt;/pre&gt;
&lt;p&gt;For the purposes of a simple install script you can call this passing &lt;code&gt;$env:userdomain&lt;/code&gt; and &lt;code&gt;$env:username&lt;/code&gt; for the user credentials. But in a more complex scenario you might want to use a group, or call it for multiple users.&lt;/p&gt;
&lt;p&gt;It's worth nothing that this function seems to fail if you try to run it before a fresh install of Docker has actually run a container. So I chose to put it into a separate script for reuse.&lt;/p&gt;
&lt;h2 id="winning"&gt;Winning!&lt;/h2&gt;
&lt;p&gt;So with that in place, you can run &lt;code&gt;docker-compose up&lt;/code&gt; for a Sitecore install, and it will successfully start:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" href="https://blog.jermdavis.dev/img/2022/01-SuccessfulCompose.png"&gt;&lt;img alt="A successful run of docker-compose starting Sitecore" src="https://blog.jermdavis.dev/img/2022/01-SuccessfulCompose.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(If you get an error starting the Docker service and Event Viewer mentions &lt;code&gt;panic.log&lt;/code&gt;, try deleting the file from &lt;code&gt;C:\ProgramData\docker&lt;/code&gt;)&lt;/p&gt;
&lt;blockquote&gt;
&lt;b&gt;&lt;i&gt;I learned an important thing while testing this:&lt;/i&gt;&lt;/b&gt; If you run up a VM in Azure to test Docker (or other virtualisation stuff) then you have to be careful which VM "size" you choose. If you pick a v1 or v2 VM you'll be able to run the script here without errors, but you'll get an error that looks like this when you try to start any container:
&lt;pre data-enlighter-theme="droide-text" data-enlighter-language="text" style="width:100%; overflow:scroll;"&gt;Error response from daemon: 
hcsshim::CreateComputeSystem 8459c6c816e764642634ce29cfee666d30834df0f2792fba9e411d11bd0c33f6: 
The virtual machine could not be started because a required feature is not installed
&lt;/pre&gt;
&lt;p&gt;After some googling, &lt;a href="https://stackoverflow.com/a/50099965" target="_blank" rel="noopener"&gt;it turns out this is because only v3 and above Azure VMs have Nested Virtualisation enabled&lt;/a&gt;. And that's required to let Docker and Hyper-V run correctly inside an Azure VM. So make sure you're careful what you pick when creating your VMs:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://blog.jermdavis.dev/img/2022/01-VM-size-choice.png"&gt;&lt;img alt="The Azure portal dropdown for picking VM size" src="https://blog.jermdavis.dev/img/2022/01-VM-size-choice.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There's a pile more work to do here, I think, before this is a fully-fledged install script, but it's a start. There's &lt;a href="https://gist.github.com/jermdavis/6fb0a6e47d6f1342c089af4c04d29c35" target="_blank" rel="noopener"&gt;a gist of this if you fancy playing with the code yourself&lt;/a&gt; - but it's very much an experiment right now. But maybe it'll be of help to you...&lt;/p&gt;
&lt;p&gt;(And if this isn't the right approach for you, &lt;a href="https://matt-rickard.com/docker-desktop-alternatives/" target="_blank" rel="noopener"&gt;there are alternatives&lt;/a&gt;)&lt;/p&gt;
</content:encoded>
			<comments xmlns="http://purl.org/rss/1.0/modules/slash/">0</comments>
		</item>
		<item>
			<title>A brief guide to Docker difficulties</title>
			<link>https://blog.jermdavis.dev/posts/2022/docker-difficulties</link>
			<description>&lt;p&gt;I spent some time working with a colleague who couldn't get his docker instance to start up happily this week. And it's reminded me that for all its positives, there are still some challenges with understanding the underlying issues when a developer container instance breaks. I realised I need a &amp;quot;go read this&amp;quot; post for the start of future discussions like this, so here are some problems you might see, and some diagnostic suggestions I wanted a convenient way to share: &lt;/p&gt;</description>
			<author>Jeremy Davis</author>
			<guid>https://blog.jermdavis.dev/posts/2022/docker-difficulties</guid>
			<pubDate>Thu, 27 Jan 2022 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;I spent some time working with a colleague who couldn't get his docker instance to start up happily this week. And it's reminded me that for all its positives, there are still some challenges with understanding the underlying issues when a developer container instance breaks. I realised I need a "go read this" post for the start of future discussions like this, so here are some problems you might see, and some diagnostic suggestions I wanted a convenient way to share: &lt;!--more--&gt;&lt;/p&gt;
&lt;p&gt;Trying to start your development instance and seeing something like this can be frustrating:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" href="https://blog.jermdavis.dev/img/2022/01-FailedDockerStart.png"&gt;&lt;img alt="A console window showing docker-compose has failed to start a traefik container" src="https://blog.jermdavis.dev/img/2022/01-FailedDockerStart.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;When something goes wrong at start-up, it's often not at all clear why. &lt;code&gt;docker-compose&lt;/code&gt; says nothing helpful. So what are some of the common issues, and how can they be mitigated?&lt;/p&gt;
&lt;h2 id="do-you-have-a-ysod"&gt;Do you have a &lt;a href="https://en.wikipedia.org/wiki/Screen_of_death#:~:text=A%20Yellow%20Screen%20of%20Death%20occurs%20when%20an%20ASP.NET%20web%20app%20encounters%20a%20problem%20and%20crashes.%5B8%5D%5Bself%2Dpublished%20source%3F%5D" target="_blank" rel="noopener"&gt;YSOD&lt;/a&gt;?&lt;/h2&gt;
&lt;p&gt;This is the problem my colleague was having. You can do &lt;code&gt;down&lt;/code&gt; and &lt;code&gt;up&lt;/code&gt; as many times as you like, but if something in your Sitecore website is throwing an unhandled exception which breaks ASP.Net, you're never going to get the site to start up in its default state.&lt;/p&gt;
&lt;p&gt;The way &lt;a href="https://traefik.io/traefik/" target="_blank" rel="noopener"&gt;Traefik&lt;/a&gt; is configured means that it relies on a health monitor endpoint in your CM container. If that does not return HTTP 200 when it is called, Traefik will not start. That leads to a really annoying situation. You're working away, and you do something that causes a YSOD. Before you fix that issue, you get distracted and end up shutting docker down. And when you come back to work, you are unable to make Sitecore start up. That makes it way harder to fix your problem you had to start with...&lt;/p&gt;
&lt;p&gt;So when you see the dreaded Traefik errors, your first response should be to work out &lt;i&gt;why&lt;/i&gt; it's failed. Some good diagnostic tactics are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Is the CM container up?&lt;/b&gt;&lt;br&gt;
The first thing to check is the state of your containers. That can give you a clue about which way your investigations should go. Traefik can fail if the CM container starts, but then goes down again. Or it can fail if it's up but returning errors serious enough to break the health endpoint. So make use of your favourite monitoring tool to check if the CM is actually running:
&lt;a href="https://blog.jermdavis.dev/img/2022/01-ContainerState.png" target="_blank"&gt;&lt;img alt="The running containers dialog from Docker Desktop - showing the state of a set of Sitecore containers" src="https://blog.jermdavis.dev/img/2022/01-ContainerState.png"&gt;&lt;/a&gt;
If the CM is down, you should look into the Service Monitor issue below, lack of memory / disk space, or similar technical issues that would prevent it from starting or from staying started. But if the CM is up you think about code and config bugs in your deployment and networking issues.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Check the container log&lt;/b&gt;&lt;br&gt;
If it's up, it's worth checking what the logs say. Both the streamed Docker logs (which cover assorted outputs of your containers, and the Sitecore logs if they've been written) Log data might point you at the Service Monitor error below, or it might point you towards the health endpoint failing. So pick a tool to look at the streamed log data initially:
&lt;a href="https://blog.jermdavis.dev/img/2022/01-CMLogsWith500.png" target="_blank" rel="noopener"&gt;&lt;img src="https://blog.jermdavis.dev/img/2022/01-CMLogsWith500.png" alt="The Visual Studio containers window, showing health monitor log errors for a Sitecore CM container"&gt;&lt;/a&gt;
The image above is an example of the &lt;code&gt;/healthz/ready&lt;/code&gt; endpoint returning 500 - which Traefik will see as a reason not to start.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;b&gt;Skip past Traefik&lt;/b&gt;&lt;br&gt;
Since Traefik is the reverse proxy for your containers, if it's down it can be difficult to see what (if any) messages are being returned if a web request fails. One trick for bypassing this issue is to make use of the fact that Docker containers are actually proper VMs - so you can connect directly to them and run other commands. That means we can fire up PowerShell inside our misbehaving CM container:&lt;/p&gt;
&lt;pre data-enlighter-theme="droide-text" data-enlighter-language="text" style="width:100%; overflow:scroll;"&gt;docker exec -it &amp;lt;your-cm-container-name&amp;gt; powershell.exe
&lt;/pre&gt;
&lt;p&gt;When you type that, you should get a new powershell session inside your container. So you can use that to directly make an HTTP request to Sitecore, and see what (if any) error comes back:&lt;/p&gt;
&lt;pre data-enlighter-language="powershell" style="width:100%; overflow:scroll;"&gt;Invoke-WebRequest http://localhost/ -UseBasicParsing
&lt;/pre&gt;
&lt;p&gt;Note that you need to use "localhost" and "http://" here - Traefik does SSL termination for you, so inside the container doesn't use HTTPS. And it also handles the DNS naming of your site - so inside the container the site is just localhost. The parameter &lt;code&gt;-UseBasicParsing&lt;/code&gt; there is required whenever you use &lt;code&gt;Invoke-WebRequest&lt;/code&gt; on a machine which doesn't have IE installed. Console-only instances of Windows Server like this don't have IE - so you'll get an error if you forget this parameter. If you're seeing 500s in the docker log stream above, chances are you're going to get a pile of red text here, indicating the real ASP.Net error. You'll likely need to scroll up a bit to see the start of the message:
&lt;a href="https://blog.jermdavis.dev/img/2022/01-WebRequestError.png" target="_blank"&gt;&lt;img src="https://blog.jermdavis.dev/img/2022/01-WebRequestError.png" alt="A powershell session showing an error message returned by Invoke-Webrequest"&gt;&lt;/a&gt;
Quite often, this is going to tell you what's wrong. (Though in some circumstances you may get more info from requesting the health endpoint url that's throwing 500s in the logs in the previous bullet) The example here (A DLL binding issue that prevented ASP.Net from starting up the Sitecore App) is pretty much what my colleague was suffering from.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once you've found your issue and corrected it, remember that you probably don't have to go through the whole up/down rigmarole. Often you can stop/delete any containers which are causing an issue, fix your problem and run &lt;code&gt;docker-compose up&lt;/code&gt; again to start up your CM or Traefik containers. They'll happily make use of the Identity Server / Solr / SQL Server ones that were (probably) already running.&lt;/p&gt;
&lt;p&gt;(Note, you also have the option to &lt;a href="https://t.co/xm31mbscmT" target="_blank" rel="noopener"&gt;disable the healthchecks that prevent you seeing the error outputs&lt;/a&gt; too. Depending on your situation, you may find that easier)&lt;/p&gt;
&lt;h2 id="youve-got-a-networking-issue"&gt;You've got a networking issue?&lt;/h2&gt;
&lt;p&gt;If you find that your CM tries to spin up, but keeps throwing "can't find my databases!" type SQL errors in the Sitecore log, then a common cause is any VPN software you might be running:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://blog.jermdavis.dev/img/2022/01-DockerSqlError.png"&gt;&lt;img alt="Log errors from SQL connections" src="https://blog.jermdavis.dev/img/2022/01-DockerSqlError.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I've had this issue - if I start my office VPN client it aggressively routes all network traffic over to my corporate network. And annoyingly that includes it grabbing the "between container" network traffic that Docker is trying to use to allow  your containers to talk to each other... A good test for whether this is your issue is to disconnect the VPN, down your containers, restart Docker Desktop and then try bringing your containers back up without the VPN connected. If it works, chances are your VPN is at fault.&lt;/p&gt;
&lt;p&gt;This can be a bit of a tricky one to solve. In my case, I had to persuade my IT Ops team to create a "&lt;a href="https://en.wikipedia.org/wiki/Split_tunneling" target="_blank" rel="noopener"&gt;split tunnel&lt;/a&gt;" configuration where only traffic for my clients and my office went over the VPN, and other (local) traffic was ignored. That allowed me to run Docker and have code in the containers access my client's networks. Great for me getting dev work done - but potentially less secure than the default VPN setup.&lt;/p&gt;
&lt;p&gt;I've also found that it's better to start the VPN before Docker Desktop, as docker is not always happy with networking changes happening after it's started up...&lt;/p&gt;
&lt;h2 id="service-monitor-on-older-containers"&gt;Service Monitor on older containers?&lt;/h2&gt;
&lt;p&gt;I'm working on a v10.0 project right now, and probably the most common failure is that the CM container's Service Monitor process fails to start. &lt;a target="_blank" href="https://sitecore.stackexchange.com/a/28676"&gt;Sitecore have addressed this one in newer releases&lt;/a&gt; if you're lucky enough to be able to upgrade your project.&lt;/p&gt;
&lt;p&gt;But if not, I've found it seems to be made worse by your custom project code and config. This error is transient, so often stopping and starting your containers can resolve it. I've also found the error seems less likely to happen if I remove my project files from the &lt;code&gt;docker\deploy\website&lt;/code&gt; folder, start up my containers, and then publish my code after vanilla Sitecore is running. Not sure if that's specific to my project or not though - but may be of help to others?&lt;/p&gt;
</content:encoded>
			<comments xmlns="http://purl.org/rss/1.0/modules/slash/">0</comments>
		</item>
		<item>
			<title>Thanks Windows Installer - you could have just asked...</title>
			<link>https://blog.jermdavis.dev/posts/2022/thanks-windows-installer</link>
			<description>&lt;p&gt;One of the things I've been doing over the festive period is reinstalling some laptops. While it's usually a slightly tedious job, something Microsoft have done to the Windows Installer of late has made picking the Windows version you want harder than it should be. So I'm leaving myself a note for next time I crash into this problem... &lt;/p&gt;</description>
			<author>Jeremy Davis</author>
			<enclosure url="https://blog.jermdavis.dev/" length="0" type="image" />
			<guid>https://blog.jermdavis.dev/posts/2022/thanks-windows-installer</guid>
			<pubDate>Mon, 01 Jan 0001 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;One of the things I've been doing over the festive period is reinstalling some laptops. While it's usually a slightly tedious job, something Microsoft have done to the Windows Installer of late has made picking the Windows version you want harder than it should be. So I'm leaving myself a note for next time I crash into this problem... &lt;!--more--&gt;&lt;/p&gt;
&lt;h2&gt;The problem&lt;/h2&gt;
&lt;p&gt;I needed to install Windows on a shiny new laptop. It had been bought with Windows Home, because there was no "I don't need to buy a new O/S" option in the shop and I already own a Windows 10 Pro license that I wanted to use on it. So it arrived with the usual bloatware installed on Home and needed wiping.&lt;/p&gt;
&lt;p&gt;So I grabbed a USB Stick, downloaded the &lt;a rel="noopener" target="_blank" href="https://www.microsoft.com/en-gb/software-download/windows10"&gt;Windows Media Creation tool&lt;/a&gt; and made myself a bootable Windows 10 install stick. (Yes, I am still &lt;a rel="noopener" target="_blank" href="https://media.giphy.com/media/STfLOU6iRBRunMciZv/giphy.gif"&gt;actively avoiding Windows 11&lt;/a&gt; for the moment) And then I went through the usualy dance of rebooting, failing to boot from USB, realising the machine ships with only "boot from SSD" enabled and fiddling with the BIOS... But after a bit of tedium I got it to boot the installer, and went through the "delete existing disk partitions" dance to clean out all the stuff that had been shipped on the laptop.&lt;/p&gt;
&lt;p&gt;Microsoft have done a bit of UX optimisation - the installer no longer asks about your license key. In fact it asks more questions about "are you ok with uploading &amp;lt;some bit of data&amp;gt; to Microsoft" than it does about your installation requirements these day.&lt;/p&gt;
&lt;p&gt;After a few minutes (and some annoying shouting from Cortana because the laptop's default volume was "high") it went through the install fine. But when it booted up, I noticed that it was running Windows Home. Which was not what I wanted...&lt;/p&gt;
&lt;h2&gt;What's going on?&lt;/h2&gt;
&lt;p&gt;I turns out that if you're installing with &lt;a rel="noopener" target="_blank" href="https://en.wikipedia.org/wiki/Unified_Extensible_Firmware_Interface"&gt;UEFI&lt;/a&gt; enabled, the installer now looks into some flash memory in your computer to see if you have a built-in windows key shipped by your &lt;a rel="noopener" target="_blank" href="https://en.wikipedia.org/wiki/Original_equipment_manufacturer"&gt;OEM&lt;/a&gt;. Since I'd bought the laptop with Windows Home installed, that's what was in this memory.&lt;/p&gt;
&lt;p&gt;So the installer was happily assuming that was the key I wanted to use for my install, and not giving me an option to change the choice.&lt;/p&gt;
&lt;p&gt;You can see what (if any) key you have stored &lt;a href="https://www.nirsoft.net/utils/product_cd_key_viewer.html" rel="noopener" target="_blank"&gt;using this viewer tool&lt;/a&gt; but be aware that as I'm witing this, Windows' built-in virus protection really doesn't seem to like it. Perhaps unsurprisingly, as Microsoft might see poking about in this data as dodgy:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" href="https://blog.jermdavis.dev/img/2022/12-KeyViewerError.png"&gt;&lt;img src="https://blog.jermdavis.dev/img/2022/12-KeyViewerError.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;So you may choose not to go down that road...&lt;/p&gt;
&lt;h2&gt;Possible solutions&lt;/h2&gt;
&lt;p&gt;Having spent an hour or so trawling through google for research, there seem to be two main ways to address this issue:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;You can let it install as above, and then use the "change my product key" option in Windows.&lt;/strong&gt;&lt;br&gt;
This will work, but it can be a bit of a hassle. Windows installs some different things for Pro compared to Home, and changing the version afterwards does not fix all of this. So if you want the full Pro experience you will need to go through the process of &lt;a rel="noopener" target="_blank" href="https://support.microsoft.com/en-us/windows/how-to-refresh-reset-or-restore-your-pc-51391d9a-eb0a-84a7-69e4-c2c1fbceb8dd"&gt;reset Windows back to the fresh-install state&lt;/a&gt; in order to get those extra bits.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Or you can make use of the installer's ability to pick up extra "unattended install" data from your install media.&lt;/strong&gt;&lt;br&gt;
It is possible to put config on your install device that says "ignore what else you may see, please install Windows Pro". That will make sure all the right files are installed, and you only need to activate the right license key afterwards to get the full Pro experience.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To my mind, the second option here was the better one.&lt;/p&gt;
&lt;p&gt;You need to create a text file named &lt;code&gt;EI.cfg&lt;/code&gt; and put it into the &lt;code&gt;sources&lt;/code&gt; folder on the USB disk that the media creator set up for you. There are lots of options you can set here, using an "ini file" style format. But the key ones to get Pro vs Home are:&lt;/p&gt;
&lt;pre data-enlighter-theme="droide-text" data-enlighter-language="text" style="width:100%; overflow:scroll;"&gt;[EditionID]
ProfessionalN
[Channel]
Retail
[VL]
0
&lt;/pre&gt;
&lt;p&gt;You can also choose other versions of Windows (If you wanted the "N" version of Pro perhaps) &lt;a href="https://superuser.com/questions/1020961/prevent-windows-10-installer-from-using-the-preinstalled-serial-key-without-disa/1608112#1608112" rel="noopener" target="_blank"&gt;using the advice in this Stack Exchange answer&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Once that file is saved, and you run through the install processs again, you'll get your chosen version. Though it still won't say anything on the screen about which version you're installing.&lt;/p&gt;
&lt;p&gt;But note that once Windows boots up, the "Activation" page in Settings may be a bit unhappy - it will know that the Home key in your BIOS memory isn't valid for the version you have installed, so you'll need to provide your valid Pro product key to allow Windows to activate. If you log in with a Microsoft Account, and you have a Pro key attached to that it may get picked up automatically. But you might need to manually enter the right key on the Activation settings page.&lt;/p&gt;
&lt;p&gt;And with that done, I was able to get back to the fun process of installing useful stuff onto these laptops, and testing out the new hardware with &lt;a rel="noopener" target="_blank" href="https://store.steampowered.com/app/846770/DYSMANTLE/"&gt;a bit of festive relaxation&lt;/a&gt;.&lt;/p&gt;
</content:encoded>
			<comments xmlns="http://purl.org/rss/1.0/modules/slash/">0</comments>
		</item>
		<item>
			<title>A blog migration story</title>
			<link>https://blog.jermdavis.dev/posts/2021/blog-migration</link>
			<description>&lt;p&gt;It's been a while coming, but over the last couple of months I've finally gone throught the process of migrating my blog content off WordPress and onto a statically hosted site.  A few people have asked me why I'd go to the trouble of doing this, so while I'm having a festive break from proper Sitecore stuff, I thought I should write about my reasoning: &lt;/p&gt;</description>
			<author>Jeremy Davis</author>
			<enclosure url="https://blog.jermdavis.dev/" length="0" type="image" />
			<guid>https://blog.jermdavis.dev/posts/2021/blog-migration</guid>
			<pubDate>Mon, 01 Jan 0001 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;It's been a while coming, but over the last couple of months I've finally gone throught the process of migrating my blog content off WordPress and onto a statically hosted site.  A few people have asked me why I'd go to the trouble of doing this, so while I'm having a festive break from proper Sitecore stuff, I thought I should write about my reasoning: &lt;!--more--&gt;&lt;/p&gt;
&lt;h2 id="why-migrate"&gt;Why migrate?&lt;/h2&gt;
&lt;p&gt;This isn't the first time I've changed providers. Back in 2014 when I first started writing, I tried &lt;a href="https://www.blogger.com/" target="_blank" rel="noopener"&gt;Blogger&lt;/a&gt; initially. That didn't last long though - I found formatting code samples to be such a pain there that it drove me to &lt;a href="https://wordpress.com/" target="_blank" rel="noopener"&gt;WordPress&lt;/a&gt; after a few months.&lt;/p&gt;
&lt;p&gt;And WordPress has kept me mostly happy for the years since. But of late they've started &lt;a href="https://en.wikipedia.org/wiki/Who_Moved_My_Cheese%3F" target="_blank" rel="noopener"&gt;moving my cheese&lt;/a&gt; quite a bit. They're in the midst of rolling out a series of enhancements towards a more modern editing UI. But in doing that they've made the workflow I've been using harder - and it's started to get on my nerves. Basically I don't get on with the new block editor.&lt;/p&gt;
&lt;p&gt;So about a year ago I started looking into the idea of moving. I toyed with a few other more recent blogging platforms, but didn't find one I liked. So I started looking at hosting it myself, in order to have more control...&lt;/p&gt;
&lt;p&gt;I tried a collection of JavaScript-based site generation tools like &lt;a href="https://www.gatsbyjs.com/" target="_blank" rel="noopener"&gt;Gatsby&lt;/a&gt;, &lt;a href="https://nextjs.org/" target="_blank" rel="noopener"&gt;NextJS&lt;/a&gt; and &lt;a href="https://hexo.io/" target="_blank" rel="noopener"&gt;Hexo&lt;/a&gt;. I quite liked Hexo, and got fairly far with creating a site based on that - but kept bumping into how my lack of JavaScript knowledge would cause issues for customising it.&lt;/p&gt;
&lt;p&gt;So I went back to the drawing board and looked for something .Net based. And after a while I came across &lt;a href="https://www.statiq.dev/" target="_blank" rel="noopener"&gt;Statiq&lt;/a&gt;. It's an ongoing project to build a modern SSG using .Net core - and it fit my skills better.&lt;/p&gt;
&lt;p&gt;So moving away from Wordpress gives me:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Better performance&lt;/strong&gt;&lt;br&gt;
Using an SSG is much better for &lt;a href="https://developers.google.com/web/tools/lighthouse" target="_blank" rel="noopener"&gt;lighthouse scores&lt;/a&gt;. Static files don't need runtime processing to render the content, so I can have pages that score very well:
&lt;a target="__blank" rel="noopener" href="https://blog.jermdavis.dev/img/2021/2021-12-Lighthouse.png"&gt;&lt;img src="https://blog.jermdavis.dev/img/2021/2021-12-Lighthouse.png"&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Control over the layout and style&lt;/strong&gt;&lt;br&gt;
There have been a few occasions over the years where I've wanted to be able to mess about with the blog theme more than the freebie WordPress behaviour lets you. Not an issue if I build the HTML myself. Though I'm sure my designer friends would say this freedom is bad for other reasons... ;-)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Picking my own domain&lt;/strong&gt;&lt;br&gt;
Again, something I could have done with paid WordPress - but is easier with a static site, and ensures I keep ownership and control over everything.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reduced risk of the platform moving out from under me&lt;/strong&gt;&lt;br&gt;
While Statiq might change in the future, it's open source, so I can always revert to a version which suits me. And while maybe one day I'll have to move hosting or DNS provider, neither of those are as big an issue as WordPress changing in ways I don't like.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So I spent some time on hacking up my own site theme, and pulled together a migration tool to transfer content. And then spent far too long fiddling with the details...&lt;/p&gt;
&lt;h2 id="what-is-the-tech-stack"&gt;What is the tech stack?&lt;/h2&gt;
&lt;p&gt;As mentioned the SSG for the new site is Statiq. It's an open source project built on .Net Core. It takes a theme built on Razor Pages, and applies it to markdown files for all your pages and posts. Statiq is just a framework for running content creation pipelines, so you can compile it into whatever application you want.&lt;/p&gt;
&lt;p&gt;It comes with pipelines which do all the common blog applications, and I found I didn't need to tweak very much of its out-of-the-box behaviour, outside of the razor files:&lt;/p&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopeners" href="https://blog.jermdavis.dev/img/2021/2021-12-Statiq.png"&gt;&lt;img src="https://blog.jermdavis.dev/img/2021/2021-12-Statiq.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;So I've got a .Net Core console app project (which happens to be running under .Net 6 - I was very pleased with how easy upgrading to that was) which generates all the mark-up, and handles the static files for the site. And I've made a couple of changes to the standard behaviour:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I modified the default code-block formatting to use the &lt;a href="https://github.com/EnlighterJS/EnlighterJS" target="_blank" rel="noopener"&gt;Enlighter.js&lt;/a&gt; framework. That gives me pretty code blocks in a style that I like.&lt;/li&gt;
&lt;li&gt;I added a pipleline to generate OpenGraph images for each post, based on &lt;a href="https://wellsb.com/csharp/aspnet/generate-images-statiq-imagesharp" target="_blank" rel="noopener"&gt;the example in this blog post&lt;/a&gt;. So social shares for any page get an image (along with other metadata) without any extra authoing effort.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both of those were pretty easy changes to make thanks to the way Statiq works.&lt;/p&gt;
&lt;p&gt;The theme then uses &lt;a href="https://tailwindcss.com/" target="_blank" rel="noopener"&gt;Tailwind CSS&lt;/a&gt; and &lt;a href="https://alpinejs.dev/" target="_blank" rel="noopener"&gt;Alpine.js&lt;/a&gt;. I've made a first pass at minimising Tailwind, but there's more to do there to get to "nice" styles.&lt;/p&gt;
&lt;p&gt;The build process for Statiq isn't that fast with 260+ posts and all their images. But it works, and the output is easy to host. I'm pushing that to a &lt;a href="https://pages.github.com/" target="_blank" rel="noopener"&gt;GitHub pages&lt;/a&gt; site, with a bit of powershell to automate the build-and-commit task. While there are lots of different static file hosting solutions I could have used for this, that was just the simplest choice.&lt;/p&gt;
&lt;p&gt;And finally, the DNS for the custom domain for the GitHub Pages site is handled by &lt;a href="https://www.cloudflare.com/" target="_blank" rel="noopener"&gt;Cloudflare&lt;/a&gt;. Nothing clever there - just a CNAME entry in the DNS that points to the relevant thing in GitHub.&lt;/p&gt;
&lt;h2 id="whats-still-to-do"&gt;What's still to do?&lt;/h2&gt;
&lt;p&gt;Plenty. Other than a few more years of writing every couple of weeks, I've got a bit of a backlog of work still to do:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There are a few migration tasks left. There are some big files left on WordPress that I don't want to host in GitHub Pages. So they need a new home. And eventually I'll need to exclude the old site from Google too.&lt;/li&gt;
&lt;li&gt;The styling is pretty hacky right now. While I've used the Tailwind CLI to minimise the default CSS file and got it fairly small, most of the UI still has lots of basic Tailwind classes applied. So eventually I'll need to work out how to put a better approach to styling in. Statiq does automatically compile sass into CSS - but I've not looked into how you can "include" other frameworks yet. So maybe I'll need to make use of a more traditional css build script. Similarly I'm pretty sure I could reduce the size of the JS being delivered with some more work.&lt;/li&gt;
&lt;li&gt;There's some particular situation which can cause the initial start-up of the Statiq build/preview engine to fail. Sometimes a bit of data in their pipeline state appears to go wrong and it gets a lot of null-value exceptions as it processes your templates. Restarting it, or clearing out the current output and cache seems to resolve the issue. But I don't know why yet, and I'd like to understand that and (hopefully) fix it. So there's a debugging task there.&lt;/li&gt;
&lt;li&gt;I'm not a fan of the current cookie banner code. Apart from not being convinced it's needed, it annoys me that it will still flash up briefly on page loads after it's been dismissed. I must be able to do better than that.&lt;/li&gt;
&lt;li&gt;And I need to find a better markdown file editor - I need to do a bit of research into customisable editors, where I have have snippet insertion, so I don't have to keep looking up the right order for brackets in markdown links...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But despite those things that need sorting, the initial migration seems to be a success. I wonder how long it'll take me to finish all those remaining migration tasks?&lt;/p&gt;
</content:encoded>
			<comments xmlns="http://purl.org/rss/1.0/modules/slash/">0</comments>
		</item>
		<item>
			<title>Is your hot disaster recovery causing a hot mess?</title>
			<link>https://blog.jermdavis.dev/posts/2021/hot-dr-hot-mess</link>
			<description>&lt;p&gt;I've had some conversations recently about odd issues with search-driven sites, whose root cause was related to disaster recovery patterns. While it's important to make sure that your business-critical website has a good backup and recovery process in place, it's also important to pay attention to how to correctly configure these scenarios...&lt;/p&gt;</description>
			<author>Jeremy Davis</author>
			<enclosure url="https://blog.jermdavis.dev/" length="0" type="image" />
			<guid>https://blog.jermdavis.dev/posts/2021/hot-dr-hot-mess</guid>
			<pubDate>Wed, 08 Dec 2021 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;I've had some conversations recently about odd issues with search-driven sites, whose root cause was related to disaster recovery patterns. While it's important to make sure that your business-critical website has a good backup and recovery process in place, it's also important to pay attention to how to correctly configure these scenarios...&lt;!--more--&gt;&lt;/p&gt;
&lt;h2 id="what-might-go-wrong"&gt;What might go wrong?&lt;/h2&gt;
&lt;p&gt;One example of the issues I've seen went something like this: The client had a website which was heavily relient on search. They had a large product offering in Sitecore, which had integrations with back-end systems to keep the content up-to-date and they had these items configured to be indexed by ContentSearch. Their site was running SolrCloud as it's back-end search technology, and it was configured with "switch on rebuild" enabled, to ensure that searches continued to work even during large, slow full index rebuilds.&lt;/p&gt;
&lt;p&gt;But there was an intermittent issue with the site. Editors would update products, publish their changes, and observe that the public site had updated correctly. But later these changes would disappear from search again. Older, out-of-date results would become visible on the site every so often. And unsurprisingly that behaviour was a problem for the client...&lt;/p&gt;
&lt;p&gt;Most people's initial assumption with an issue like this would be to look at Solr. If the search results go from "correct" to "wrong" without obvious user intervention then that implies a problem with how data is indexed. But Solr itself isn't the root cause here. Spending time examining the details of the search configuration, and how it processes data at runtime will often show up the same core problem: Solr will happily index the correct data, but every so often it will receive an unexpected "swap aliases" command from the "switch on rebuild" process. That causes the search engine to start serving content from an old (out of date) version of the index - leading to the odd results users were seeing.&lt;/p&gt;
&lt;p&gt;But why would it decide to swap back to the old index? The answer may well be hiding in your disaster recovery setup..&lt;/p&gt;
&lt;h2 id="what-patterns-are-people-aiming-for"&gt;What patterns are people aiming for?&lt;/h2&gt;
&lt;p&gt;For search infrastructure, fault-tolerance is fairly easy with SolrCloud. You spin up three or more Solr nodes, and configure them as a load balaced cluster. Then you configure your indexes as replicated across those nodes. So if any node fails, queries and index operations are handled by other nodes, while you recover the broken one. For more scale and tolerance to faults, you spin up more nodes. And, as noted, Sitecore is often configured with "switch on rebuild" to ensure you always have an index available to query - even in the middle of a rebuild operation.&lt;/p&gt;
&lt;p&gt;To get fault tolerance for your website you spin up extra servers too. ARM Templates or Kubernetes config can make this pretty easy. It's commonly done for CD servers, but some clients I come across want uptime guarantees and service recovery KPIs to apply to their authoring environment too. So in their minds it makes sense to spin up extra copies of their standard content management role in order to ensure they have a backup in case of disaster.&lt;/p&gt;
&lt;h2 id="so-why-might-it-break"&gt;So why might it break?&lt;/h2&gt;
&lt;p&gt;The underlying issue here is indexing strategies. Your default Sitecore CM instance is configured to be the indexing role as well as the CM role for your website. That means it runs the processes which watch your databases for changes and publishing events, and when these happen it fires off the commands and data to Solr to update indexes.&lt;/p&gt;
&lt;p&gt;Most of the time that indexing process will work fine - but as Sitecore note in their documentation, you should only have one server who is responsible for index updates at any time. So if you spin up a "hot backup" content management server using the default CM config you're breaking that rule. You end up with two severs who both think they should be maintaining the Solr indexes. And that means every so often they will trip over each other and mess up your indexes.&lt;/p&gt;
&lt;p&gt;You start to see situations where your backup CM server triggers an index swap in a situation it shouldn't have - where the "offline" index is not actually up-to-date. And that makes it look like content is dropping out of your search indexes.&lt;/p&gt;
&lt;h2 id="how-should-we-fix-this"&gt;How should we fix this?&lt;/h2&gt;
&lt;p&gt;&lt;a target="_blank" rel="noopener" href="https://doc.sitecore.com/en/developers/92/platform-administration-and-architecture/enable-the-indexing-sub-role.html"&gt;Sitecore's documentation for SolrCloud and switch-on-rebuild&lt;/a&gt; states that in any deployment, precisely one server must be responsible for indexing:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://blog.jermdavis.dev/img/2021/2021-11-SitecoreDocsNote.png" target="_blank"&gt;&lt;img alt="Note in Sitecore's doc - only one indexing role allowed" src="https://blog.jermdavis.dev/img/2021/2021-11-SitecoreDocsNote.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;To achive this, you have three broad choices:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;b&gt;Follow the documenation - disable indexing on all but one CM&lt;/b&gt;&lt;br&gt;
If you have to run backup CMs up all the time, then you can follow the documentation and use role based config to ensure that you only ever have one of them which is running the indexing role. That gives you the advantage of having your hot backup CM, while keeping a supported setup. But a disadvantage here is that you have work to do in order to ensure that your CM instances get the right config. In the scenario that your indexing-enabled CM blows up, you have to make sure that another server will pick up this role. And that may be a manual task. 
&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Use infrastructure automation to enable your backup CM&lt;/b&gt;&lt;br&gt;
You don't have to keep a backup running all the time. You could have a mechanism to (fairly quickly) fire up a new instance in the event of disaster, but not have it up and running during normal operations. The key advantage here is probably cost - not running a server means you don't pay for it. But the related disadvantage is that in an outage you'll need to wait for this automation to complete before you have a CM again. Your choices for doing that include:
  &lt;ul&gt;
    &lt;li&gt;Keep an ARM Template or the relevant Kubernetes config files available, so you can run them to fire up a new CM instance in an emergency. That process can be automated potentially.&lt;/li&gt;
    &lt;li&gt;Or if you run in an IaaS pattern, have the instance installed but the VM / server stopped.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Configure a separate Indexing role&lt;/b&gt;&lt;br&gt;
Sitecore supports pulling the indexing role out to a separate server. That might have licensing and runtime cost implications for you, and requires a bit of specific configuration/deployment work, but it allows your multiple CMs (who all have the same config) to share one indexing service. The advantage here is both that you have an instant backup CM in the event of an issue, and that you get to have all your CMs running the same configuration. But the downside here is cost - you're paying to run yet another role for the indexing instance.
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Which of these works best for you will depend on other criteria of your project of course. But you need to follow the Sitecore's rules to avoid having issues.&lt;/p&gt;
&lt;blockquote&gt;
&lt;b&gt;&lt;i&gt;Updated to add:&lt;/i&gt;&lt;/b&gt;
&lt;p&gt;After I published this, one of my colleagues pointed out another fun edge case here. There's a config setting which controls whether Sitecore tries to force aliases to exist when the site starts up:&lt;/p&gt;
&lt;pre data-enlighter-language="xml" style="width:100%; overflow:scroll;"&gt;&amp;lt;!--  ENFORCES ALIAS CREATION ON INDEX INITIALIZATION
            If enabled, index aliases will be created on Solr during the index initialization process.
            Default value: false
--&amp;gt;
&amp;lt;setting name="ContentSearch.Solr.EnforceAliasCreation" value="false" /&amp;gt;
&lt;/pre&gt;
&lt;p&gt;If you have this set to true, even if a CM server has all its index strategies set to "manual", it will still end up resetting the active alias to the "non rebuild" one each time the Sitecore process recycles. And that may well be the wrong one based on the current state of your public site...&lt;/p&gt;
&lt;p&gt;So worth checking the state of that setting if you're seeing odd behaviour with indexes, but you thought you'd followed rules above.&lt;/p&gt;
&lt;/blockquote&gt;
</content:encoded>
			<comments xmlns="http://purl.org/rss/1.0/modules/slash/">0</comments>
		</item>
		<item>
			<title>Shipping custom logs from your v10 containers</title>
			<link>https://blog.jermdavis.dev/posts/2021/shipping-custom-logs-from-your-v10-containers</link>
			<description>&lt;p&gt;My work on a container-based v10.0 project keeps raising interesting challenges – things that don’t work quite the same way in Docker or Kubernetes, compared to the old world of &amp;quot;bare metal&amp;quot; installs of Sitecore. Custom log files are an example here...&lt;/p&gt;</description>
			<author>Jeremy Davis</author>
			<enclosure url="https://blog.jermdavis.dev/" length="0" type="image" />
			<guid>https://blog.jermdavis.dev/posts/2021/shipping-custom-logs-from-your-v10-containers</guid>
			<pubDate>Mon, 01 Jan 0001 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;My work on a container-based v10.0 project keeps raising interesting challenges – things that don’t work quite the same way in Docker or Kubernetes, compared to the old world of "bare metal" installs of Sitecore. Custom log files are an example here...&lt;!--more--&gt;&lt;/p&gt;
&lt;p&gt;I realised recently that we had some custom code in our solution, whose log data was not appearing in the Docker streamed logs. (And hence wasn’t visible in the Kubernetes container log output either) After a bit of digging I released this was because the developers had quite sensibly moved these log entries to a separate log file. Turns out that the log streaming does not pick up all logs – you have to be specific:&lt;/p&gt;
&lt;h2&gt;How does it work?&lt;/h2&gt;
&lt;p&gt;Inside your containers, a tool called &lt;code&gt;LogMonitor.exe&lt;/code&gt; is running. It uses disk monitoring (and other techniques, potentially) to monitor log data, and when it sees changes it streams these to “standard output".&lt;/p&gt;
&lt;p&gt;Your container orchestrator is picking up that streamed data, and sending it to whatever console or log aggregation framework your using. That might be AppInsights or Prometheus from Kubernetes in production, and it might be the Visual Studio containers window or a console under Docker.&lt;/p&gt;
&lt;p&gt;By default, this is set up to stream IIS logs and the main Sitecore log. So what do we do if we want other log files?&lt;/p&gt;
&lt;h2&gt;Extending this&lt;/h2&gt;
&lt;p&gt;If you look inside your Sitecore CM or CD containers, LogMonitor sits in a folder under the root:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://blog.jermdavis.dev/img/2021/2021-10-logmonitor.png" target="_blank"&gt;&lt;img alt="Log Monitor" src="https://blog.jermdavis.dev/img/2021/2021-10-logmonitor.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;By default it’s started by the entrypoint script for the container, and it reads is configuration settings from that &lt;code&gt;json&lt;/code&gt; file sitting next to it.&lt;/p&gt;
&lt;p&gt;It's default state is:&lt;/p&gt;
&lt;pre data-enlighter-language="jscript" style="width:100%; overflow:scroll;"&gt;{
    "LogConfig": {
      "sources": [
        {
          "type": "EventLog",
          "startAtOldestRecord": false,
          "eventFormatMultiLine": false,
          "channels": [
            {
              "name": "system",
              "level": "Error"
            }
          ]
        },
        {
          "type": "File",
          "directory": "c:\\inetpub\\logs",
          "filter": "*.log",
          "includeSubdirectories": true
        },
        {
          "type": "File",
          "directory": "c:\\inetpub\\wwwroot\\App_data\\logs",
          "filter": "log.*.txt",
          "includeSubdirectories": false
        }
      ]
    }
  }
}
&lt;/pre&gt;
&lt;p&gt;So to add extra log files we can modify this. There’s some &lt;a href="https://github.com/microsoft/windows-container-tools/wiki/Authoring-a-Config-File" rel="noopener" target="_blank"&gt;documentation available on GitHub&lt;/a&gt; because it’s not just disk files you can process here. But I’m only interested in other Sitecore logs for the moment...&lt;/p&gt;
&lt;p&gt;So we could change the existing pattern there to "&lt;code&gt;*.txt&lt;/code&gt;" to bring in everything from the logs folder. But I wanted to be a bit more subtle. I tried adding an extra source which would cover just the files I care about:&lt;/p&gt;
&lt;pre data-enlighter-language="jscript" style="width:100%; overflow:scroll;"&gt;{
    "type": "File",
    "directory": "c:\\inetpub\\wwwroot\\App_data\\logs",
    "filter": "MyCustomFile.log.*.txt",
    "includeSubdirectories": false
}
&lt;/pre&gt;
&lt;p&gt;That block gets appended after the file source for the main Sitecore logs, as part of the array for "sources".&lt;/p&gt;
&lt;p&gt;But to make this work, we need to get this into our container images. How do we manage that? Extending the base image build...&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/Sitecore/docker-examples/tree/develop/custom-images/docker/build/cm" rel="noopener" target="_blank"&gt;example container setup for Sitecore includes a DockerFile&lt;/a&gt; for extending the base CM container. (You may want to do this on other roles too, of course – similar patterns apply)&lt;/p&gt;
&lt;p&gt;We can extend that file to overwrite the default config with out version. Use the VS container browser shown above to find the file and right-click "open" it to see the contents. You can then modify this, and save a copy of your changes in your docker image build folder.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://blog.jermdavis.dev/img/2021/2021-10-dockerfile.png" target="_blank"&gt;&lt;img alt="DockerFile" src="https://blog.jermdavis.dev/img/2021/2021-10-dockerfile.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can then add a simple "copy" operation into your Dockerfile:&lt;/p&gt;
&lt;pre data-enlighter-theme="droide-text" data-enlighter-language="text" style="width:100%; overflow:scroll;"&gt;# Update Log Monitor config
COPY CustomLogMonitorConfig.json C:\LogMonitor\LogMonitorConfig.json
&lt;/pre&gt;
&lt;p&gt;That will ensure your modified file will end up in the container, ready to run on startup. Note that you will need to rebuild your container images for that to take effect.&lt;/p&gt;
&lt;p&gt;But once that’s done, the extra data should appear in your streamed logs:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://blog.jermdavis.dev/img/2021/2021-10-extralogs.png" target="_blank"&gt;&lt;img alt="Extra Logs" src="https://blog.jermdavis.dev/img/2021/2021-10-extralogs.png"&gt;&lt;/a&gt;&lt;/p&gt;
</content:encoded>
			<comments xmlns="http://purl.org/rss/1.0/modules/slash/">0</comments>
		</item>
		<item>
			<title>What happened to my “item:deleted” event?</title>
			<link>https://blog.jermdavis.dev/posts/2021/what-happened-to-my-itemdeleted-event</link>
			<description>&lt;p&gt;My QA team had a deployment issue recently, where Azure DevOps failed to successfully release to a couple of servers. The reason for the failure wasn't obvious to me immediately, so here's a quick write-up for Google, in the hope it saves some other people.&lt;/p&gt;</description>
			<author>Jeremy Davis</author>
			<enclosure url="https://blog.jermdavis.dev/" length="0" type="image" />
			<guid>https://blog.jermdavis.dev/posts/2021/what-happened-to-my-itemdeleted-event</guid>
			<pubDate>Mon, 01 Jan 0001 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;My QA team had a deployment issue recently, where Azure DevOps failed to successfully release to a couple of servers. The reason for the failure wasn't obvious to me immediately, so here's a quick write-up for Google, in the hope it saves some other people.&lt;!--more--&gt;&lt;/p&gt;
&lt;h2&gt;The reported error&lt;/h2&gt;
&lt;p&gt;The DevOps release pipeline had failed. It was the Unicorn sync step which reported an error, but the error messages were not initially helpful:&lt;/p&gt;
&lt;a href="/img/2021/releaseerror.png"&gt;
&lt;img src="https://blog.jermdavis.dev/img/2021/releaseerror.png" alt="Release Error"&gt;
&lt;/a&gt;
&lt;p&gt;For Google's benefit, the error is here:&lt;/p&gt;
&lt;pre data-enlighter-theme="droide-text" data-enlighter-highlight="15" data-enlighter-language="text" style="width:100%; overflow:scroll;"&gt;2021-09-06T10:56:24.4434898Z ##[section]Starting: Run Unicorn Sync
2021-09-06T10:56:24.4576402Z ==============================================================================
2021-09-06T10:56:24.4576705Z Task         : PowerShell
2021-09-06T10:56:24.4576990Z Description  : Run a PowerShell script on Linux, macOS, or Windows
2021-09-06T10:56:24.4577248Z Version      : 2.190.0
2021-09-06T10:56:24.4577458Z Author       : Microsoft Corporation
2021-09-06T10:56:24.4577771Z Help         : https://docs.microsoft.com/azure/devops/pipelines/tasks/utility/powershell
2021-09-06T10:56:24.4578219Z ==============================================================================
2021-09-06T10:56:25.3011750Z Generating script.
2021-09-06T10:56:25.3420551Z ========================== Starting Command Output ===========================
2021-09-06T10:56:25.3660200Z ##[command]"C:\Windows\System32\WindowsPowerShell\v1.0\powershell.exe" -NoLogo -NoProfile -NonInteractive -ExecutionPolicy Unrestricted -Command ". 'C:\azagent\A1\_work\_temp\6a50dc74-9a04-4072-afd1-03306e0b3fb2.ps1'"
2021-09-06T10:56:25.6931500Z Starting Unicorn sync
2021-09-06T10:56:26.4749680Z Sync-Unicorn: Executing Sync...
2021-09-06T10:56:26.7585296Z Sync-Unicorn : Exception calling "GetResponse" with "0" argument(s): "The
2021-09-06T10:56:26.7585814Z remote server returned an error: (500) Internal Server Error."
2021-09-06T10:56:26.7586285Z At C:\azagent\A1\_work\_temp\6a50dc74-9a04-4072-afd1-03306e0b3fb2.ps1:9 char:1
2021-09-06T10:56:26.7586747Z + Sync-Unicorn -ControlPanelUrl 'https://my-server-name/un ...
2021-09-06T10:56:26.7587192Z + ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
2021-09-06T10:56:26.7587616Z     + CategoryInfo          : NotSpecified: (:) [Sync-Unicorn], MethodInvocationException
2021-09-06T10:56:26.7588307Z     + FullyQualifiedErrorId : WebException,Sync-Unicorn
2021-09-06T10:56:26.7588676Z
2021-09-06T10:56:26.8984825Z ##[error]PowerShell exited with code '1'.
2021-09-06T10:56:26.9490148Z ##[section]Finishing: Run Unicorn Sync
&lt;/pre&gt;
&lt;p&gt;But basically all it says is that there was a 500 error calling Unicorn's sync endpoint.&lt;/p&gt;
&lt;h2&gt;A better error&lt;/h2&gt;
&lt;p&gt;That's not enough to solve the problem, so I needed to get some more details. The obvious thing to try was a manual sync of Unicorn. So loaded up &lt;code&gt;/unicorn.aspx&lt;/code&gt; and told it to sync everything. That told me two things initially: Firstly that the actual seralised items were syncing ok. And secondly that the error was actually happening during the automatic publish afterwards. It failed with this display in the UI:&lt;/p&gt;
&lt;a href="/img/2021/unicornerror.png"&gt;
&lt;img src="https://blog.jermdavis.dev/img/2021/unicornerror.png" alt="Detailed error"&gt;
&lt;/a&gt;
&lt;p&gt;Again, for Google's benefit:&lt;/p&gt;
&lt;pre data-enlighter-theme="droide-text" data-enlighter-language="text" style="width:100%; overflow:scroll;"&gt;Message[1]: Ensure definition type did not complete successfully. StatusCode: 500, ReasonPhrase: 'Internal Server Error', Version: 1.1, Content: System.Net.Http.StreamContent, Headers:
{
Cache-Control: private
Date: Mon, 06 Sep 2021 10:56:26 GMT
Server: Microsoft-IIS/8.5
X-AspNet-Version: 4.0.30319
X-Powered-By: ASP.NET
Content-Length: 7903
Content-Type: text/html; charset=utf-8
}
Source[1]: Sitecore.Xdb.Common.Web
at Sitecore.Xdb.Common.Web.Synchronous.SynchronousExtensions.SuspendContextLock[TResult](Func`1 taskFactory)
at Sitecore.ExperienceAnalytics.Core.Repositories.ReferenceData.ExperienceAnalyticsSegmentReader.GetDefinitionTypeKey()
at Sitecore.ExperienceAnalytics.Core.Repositories.ReferenceData.ExperienceAnalyticsSegmentReader.Get(Guid key, NameValueCollection readingPreferences)
at Sitecore.ExperienceAnalytics.Client.Deployment.Events.SegmentDeployedEventHandler.DeleteSegment(Item deletedItem)
at Sitecore.Events.Event.EventSubscribers.RaiseEvent(String eventName, Object[] parameters, EventResult result)

101216 11:56:26 ERROR Failed to delete the item. Item ID: {1D54ADFD-3D04-49FF-9FA1-BEC77042AE65}, database: web
Exception: System.AggregateException
Message: One or more exceptions occurred while processing the subscribers to the 'item:deleted' event.
Source: Sitecore.Kernel
at Sitecore.Events.Event.EventSubscribers.RaiseEvent(String eventName, Object[] parameters, EventResult result)
at Sitecore.Events.Event.RaiseEvent(String eventName, Object[] parameters)
at System.EventHandler`1.Invoke(Object sender, TEventArgs e)
at Sitecore.Data.Engines.EngineCommand`2.RaiseEvent[TArgs](EventHandler`1 handlers, Func`2 argsCreator)
at Sitecore.Data.Engines.EngineCommand`2.Execute()
at Sitecore.Data.Engines.DataEngine.DeleteItem(Item item)
&lt;/pre&gt;
&lt;p&gt;That error's telling us that what actually happened was that the &lt;code&gt;item:deleted&lt;/code&gt; event has a subscriber that connects to xDB. And that's what's failing here.&lt;/p&gt;
&lt;h2&gt;A soluition – and some facepalming&lt;/h2&gt;
&lt;p&gt;I spent a bit of time reading the errors above, before spotting this bit:&lt;/p&gt;
&lt;pre data-enlighter-theme="droide-text" data-enlighter-language="text" style="width:100%; overflow:scroll;"&gt;Message[1]: Ensure definition type did not complete successfully. StatusCode: 500, ReasonPhrase: 'Internal Server Error'
&lt;/pre&gt;
&lt;p&gt;And a bit of Googling pointed me to this article: "&lt;a href="https://andrewwburns.com/2019/02/07/sitecore-system-invalidoperationexception-ensure-definition-type-did-not-complete-successfully/" target="_blank"&gt;SITECORE: SYSTEM.INVALIDOPERATIONEXCEPTION: ENSURE DEFINITION TYPE DID NOT COMPLETE SUCCESSFULLY&lt;/a&gt;" and the sudden realisation that this was actually really obvious...&lt;/p&gt;
&lt;p&gt;That article points out that the message in the Sitecore logs above correlates to a message in the xConnect logs which is much more obvious:&lt;/p&gt;
&lt;pre data-enlighter-theme="droide-text" data-enlighter-language="text" style="width:100%; overflow:scroll;"&gt;[Error] XConnect Web Application Error: “System.ApplicationException:
Exception trying to intialize Service Collection and Provider for for WebAPI Dependency Resolver, Inner Exception:
Required license is missing: Sitecore.xDB.Base —&amp;gt; Sitecore.Nexus.Licensing.LicenseException: Required license is missing: Sitecore.xDB.Base
&lt;/pre&gt;
&lt;p&gt;Hence the facepalming... This whole business was another "our company's license has expired" issue – &lt;a href="https://blog.jermdavis.dev/posts/2021/sitecore-containers-and-expired-licenses" target="_blank"&gt;like the Docker issues I saw recently&lt;/a&gt;. My colleagues had correctly updated the license file for the XM roles, but it seems they forgot to update xConnect's copy of the license file. Ooops.&lt;/p&gt;
&lt;p&gt;But, problem solved, as everything sorted itself out when I updated that missed license file. So a big thank you to &lt;a href="https://twitter.com/AndrewWBurns/" rel="noopener" target="_blank"&gt;Andy Burns&lt;/a&gt; for the blog post that helped me here.&lt;/p&gt;
</content:encoded>
			<comments xmlns="http://purl.org/rss/1.0/modules/slash/">0</comments>
		</item>
		<item>
			<title>Symposium's vision for SaaS</title>
			<link>https://blog.jermdavis.dev/posts/2021/symposiums-vision-for-saas</link>
			<description>&lt;p&gt;There was a lot of interesting information releases during &lt;a href="https://symposium.sitecore.com/" rel="noopener" target="_blank"&gt;Sitecore Symposium&lt;/a&gt; last week. Since I had to summarise this for a work event, I figured I should reuse those thoughts, and write up a brief summary of some of the announcements that caught my attention, and (importantly) Sitecore's vision their future SaaS product: &lt;/p&gt;</description>
			<author>Jeremy Davis</author>
			<enclosure url="https://blog.jermdavis.dev/" length="0" type="image" />
			<guid>https://blog.jermdavis.dev/posts/2021/symposiums-vision-for-saas</guid>
			<pubDate>Mon, 01 Jan 0001 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;There was a lot of interesting information releases during &lt;a href="https://symposium.sitecore.com/" rel="noopener" target="_blank"&gt;Sitecore Symposium&lt;/a&gt; last week. Since I had to summarise this for a work event, I figured I should reuse those thoughts, and write up a brief summary of some of the announcements that caught my attention, and (importantly) Sitecore's vision their future SaaS product: &lt;!--more--&gt;&lt;/p&gt;
&lt;h2&gt;There's lots of stuff going on:&lt;/h2&gt;
&lt;p&gt;Before I get into the SaaS business, it's worth noting it was a busy event for anouncements generally. Some highlights we heard:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;b&gt;Sitecore 10.2 will be released in November&lt;/b&gt;&lt;br&gt;
Windows Server 2022 support. .Net Core upgraded to V3 for the relevant roles. Analytics reporting improvements. Ability to delete interaction data more easily. New CLI features like field exclusion for serialisation, resource file generation and search index rebuild. (The CLI improvements are also available for 10.1) Plus the usuall collection of bug fixes and performance tweaks.
&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;We now know the new branding for all the recent acquisitions&lt;/b&gt;&lt;br&gt;
Instead of Boxever, Four51, MooSend and Reflektion, we now have: Sitecore CDP / Sitecore Personalise, Sitecore OrderCloud, Sitecore Send and Sitecore Search / Sitecore Discover. Names we'll be hearing about much more in the future, I suspect.
&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;Content Hub 4.1 in a month or so&lt;/b&gt;&lt;br&gt;
New schema features for references between content items. More media types supported. Extensibility for media previews.
&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;New headless framework release&lt;/b&gt;&lt;br&gt;
Updated to newer NextJS and Vue versions. Ability to publish markup from MVC components to headless services.
&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;Updates to SXA in 10.2&lt;/b&gt;&lt;br&gt;
Scriban template improvements. Better data sharing for multi-site setups. Bootstrap 5 support.
&lt;/li&gt;
&lt;li&gt;
&lt;b&gt;Updates to Horizon in 10.2&lt;/b&gt;&lt;br&gt;
Improved editing experience for SXA components. Docker image supporting process isolation. UI improvements. New "content explorer" view listing all items.
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;On top of that, the SaaS vision is very interesting:&lt;/h2&gt;
&lt;p&gt;But the real excitement is with the vision for Sitecore's future SaaS offering. While we've had Content Hub as a SaaS content tool for some time now, it's had some key weak spots compared to what we're used to with classic Sitecore: It's not great with trees of content, and it doesn't provide any way to compose UI components together into a page. Those caveats mean it's not the right choice for a variety of scenarios.&lt;/p&gt;
&lt;p&gt;So Sitecore have started to talk about an alternative approach: offering a package built around the classic Sitecore XM product, but hosted via SaaS. The phrase Dave O'Flanagan used in his keynote was "The no-compromise CMS" – because it's trying to take the best bits of the traditional model and the best bits of the headless / JAMStack model, and blend them together.&lt;/p&gt;
&lt;p&gt;The high-level picture he talked about looks like this:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://blog.jermdavis.dev/img/2021/2021-10-saas-diagram.png" target="_blank"&gt;&lt;img alt="SaaS Diagram" src="https://blog.jermdavis.dev/img/2021/2021-10-saas-diagram.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;So what are all the boxes on this diagram going to do for us?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Experience Manager Cloud&lt;/b&gt;&lt;br&gt;
You'll need somewhere to store your content in this model, and the technology in play is based on the classic Sitecore XM platform. It will be wrapped up in some clever SaaS sauce, so instances are automagically managed for you – it will sort out databases and Solr. When you have customisations to deploy, you'll use a GitOps approach to deployment – push to a source control branch, and those changes get deployed to your instance. It will run headless services, which will be key to how it serves content because it will be CM-only, and this won't be exposed to the public internet. Which means it never needs to scale for load – keeping the implementation simpler.
&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Experience Edge&lt;/b&gt;&lt;br&gt;
This isn't new (&lt;a href="https://doc.sitecore.com/en/developers/101/developer-tools/sitecore-experience-edge-for-xm.html" rel="noopener" target="_blank"&gt;you can play with it now, with your current JSS/Headless sites&lt;/a&gt;) but it's really fundamental for the new model. Edge is a cloud-scale cache for your Headless Services data. Your CM instance can publish its content, media and layout data to this service, so that your headless front-end code can read the data from here. It replaces the need for the CD servers the "old" JSS approach would have used to do this job. The magic here is that because it's a CDN-style edge cache, it scales to meet the needs of your front-end automatically. So you no longer need to provision content delivery servers.
&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Content Hub&lt;/b&gt;&lt;br&gt;
There is a role for Content Hub here, alongside XM – as the DAM for selecting media from.
&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Symphony&lt;/b&gt;&lt;br&gt;
This is the brand name they're giving to an enhanced, SaaS-hosted evolution of the Horizon editor. It gives you the full WYSIWYG editing experience for your JAMStack-style sites. It's also integrated with Personalise, to let you manage your personalisation work and examine its outcomes. Sitecore argue that this is an important differentiator for their offering, because it's bringing the editorial flexibility we've been used to with the classic CMS to the JAMStack site.
&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Personalise&lt;/b&gt;&lt;br&gt;
Since XM doesn't include any of the old XConnect-powered personalisation, there needs to be something to provide those services in this new model. And the "Personalise" product is a cut-down set of tools from the Boxever suite. We don't know much about what the scope of this product's set of services will be yet, however. So it will be interesting to see what features are available here by default.
&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Vercel&lt;/b&gt;&lt;br&gt;
The final thing you need for this system is somewhere to serve the front-end code for your website from. As mentioned, we don't have any CD servers in this world. Experience Cloud has a focus on Next.js for building your site UI, so Sitecore have chosen to partner with &lt;a href="https://vercel.com/" rel="noopener" target="_blank"&gt;Vercel&lt;/a&gt; to give you somewhere to host it. They provide a GitOps way to deploy your code quickly, and CDN-style scaling behaviour to help you cope with load without effort. But critically the infrastructure here understands the build process for your Next.js code – so it can automatically perform tasks like static site generation whenever your code gets update, or when Experience Edge triggers a webhook to signal new content has been published.
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;While the diagram doesn't show the other new systems Sitecore has aquired, it's clear that things like Search, OrderCloud and Send will be integratable with this model too.&lt;/p&gt;
&lt;p&gt;An interesting point about the approach above, is that it's basically the next step on from what you could do with an XM 10.2 / Headless deployment in Managed Cloud. And Sitecore have said if you can migrate your site over to be able to run in that pattern, it will have a very simple migration path to the SaaS service once it's released.&lt;/p&gt;
&lt;p&gt;We've got a bit to wait to see the details of this, however – Sitecore are saying we'll see initial releases in spring next year. But this is another driver for me to finally wrap my head around headless development for Sitecore. It seems like it's pretty certain to become the new normal for projects in the future. And it looks a flexible, powerful future too.&lt;/p&gt;
&lt;p&gt;Exciting times...&lt;/p&gt;
</content:encoded>
			<comments xmlns="http://purl.org/rss/1.0/modules/slash/">0</comments>
		</item>
		<item>
			<title>Sitecore containers and expired licenses</title>
			<link>https://blog.jermdavis.dev/posts/2021/sitecore-containers-and-expired-licenses</link>
			<description>&lt;p&gt;Sometimes you have a problem that you should absolutely have seen coming. The annual &amp;quot;the company's Sitecore license has expired&amp;quot; fun is very much one of those things. But I'd not thought about this in advance, and the license expired while I was on holiday this year. It caused my team a load of hassle... But I have a plan to avoid this pain in the future: &lt;/p&gt;</description>
			<author>Jeremy Davis</author>
			<enclosure url="https://blog.jermdavis.dev/" length="0" type="image" />
			<guid>https://blog.jermdavis.dev/posts/2021/sitecore-containers-and-expired-licenses</guid>
			<pubDate>Mon, 01 Jan 0001 00:00:00 GMT</pubDate>
			<content:encoded>&lt;p&gt;Sometimes you have a problem that you should absolutely have seen coming. The annual "the company's Sitecore license has expired" fun is very much one of those things. But I'd not thought about this in advance, and the license expired while I was on holiday this year. It caused my team a load of hassle... But I have a plan to avoid this pain in the future: &lt;!--more--&gt;&lt;/p&gt;
&lt;h2&gt;The issue&lt;/h2&gt;
&lt;p&gt;When you're running Sitecore in containers, it's not necessarily obvious when your license expires. The containers can start up – but you'll end up with some errors inside them. The identity service will fairly rapidly throw an exception in its logs:&lt;/p&gt;
&lt;pre data-enlighter-theme="droide-text" data-enlighter-language="text" style="width:100%; overflow:scroll;"&gt;&amp;lt;Source&amp;gt;EventLog&amp;lt;/Source&amp;gt;&amp;lt;Time&amp;gt;2021-09-03T19:33:25.000Z&amp;lt;/Time&amp;gt;&amp;lt;LogEntry&amp;gt;&amp;lt;Channel&amp;gt;System&amp;lt;/Channel&amp;gt;&amp;lt;Level&amp;gt;Error&amp;lt;/Level&amp;gt;&amp;lt;EventId&amp;gt;701&amp;lt;/EventId&amp;gt;&amp;lt;Message&amp;gt;Task Scheduler service failed to start Task Compatibility module. Tasks may not be able to register on previous Window versions. Additional Data: Error Value: 2147942450.&amp;lt;/Message&amp;gt;&amp;lt;/LogEntry&amp;gt;
Unhandled Exception: Sitecore.Framework.Runtime.Licensing.Exceptions.SitecoreLicenseInvalidOperationException: Invalid or expired license. [Raw]
[2021-09-03T19:33:31.000Z][LOGMONITOR] INFO: Entrypoint processs exit code: -532462766
   at Sitecore.Framework.Runtime.Licensing.LicenseValidator.LoadLicense(License license)
   at Sitecore.Framework.Runtime.Commands.SitecoreHostCommand.OnExecuteAsync(CommandLineApplication app)
   at McMaster.Extensions.CommandLineUtils.Conventions.ExecuteMethodConvention.InvokeAsync(MethodInfo method, Object instance, Object[] arguments)
   at McMaster.Extensions.CommandLineUtils.Conventions.ExecuteMethodConvention.OnExecute(ConventionContext context, CancellationToken cancellationToken)
   at McMaster.Extensions.CommandLineUtils.Conventions.ExecuteMethodConvention.&amp;lt;&amp;gt;c__DisplayClass0_0.&amp;lt;&amp;lt;Apply&amp;gt;b__0&amp;gt;d.MoveNext()
--- End of stack trace from previous location where exception was thrown ---
   at McMaster.Extensions.CommandLineUtils.CommandLineApplication.ExecuteAsync(String[] args, CancellationToken cancellationToken)
   at McMaster.Extensions.CommandLineUtils.CommandLineApplication.ExecuteAsync[TApp](CommandLineContext context, CancellationToken cancellationToken)
   at Sitecore.Program.&amp;lt;Main&amp;gt;(String[] args)
&lt;/pre&gt;
&lt;p&gt;But the CM container will give a less obvious error:&lt;/p&gt;
&lt;pre data-enlighter-theme="droide-text" data-enlighter-language="text" style="width:100%; overflow:scroll;"&gt;2021-09-03 19:34:33 ::1 GET /healthz/ready - 80 - ::1 Mozilla/5.0+(Windows+NT;+Windows+NT+10.0;+en-US)+WindowsPowerShell/5.1.17763.1971 - 500 0 0 30804
2076 20:35:07 INFO  HttpModule is being initialized
2260 20:35:17 INFO  **************************************************
2260 20:35:17 WARN  Sitecore shutting down
2260 20:35:17 WARN  Shutdown message: Initialization Error
HostingEnvironment initiated shutdown
2021-09-03 19:35:07 ::1 GET /healthz/ready - 80 - ::1 Mozilla/5.0+(Windows+NT;+Windows+NT+10.0;+en-US)+WindowsPowerShell/5.1.17763.1971 - 500 0 0 4130
&lt;/pre&gt;
&lt;p&gt;And if you're running XP, that will get errors for xConnect too:&lt;/p&gt;
&lt;pre data-enlighter-theme="droide-text" data-enlighter-language="text" style="width:100%; overflow:scroll;"&gt;2021-09-03 20:34:08.802 +01:00 [Error] XConnect Web Application Error: "System.ApplicationException: Exception trying to initialize Service Collection and Provider for WebAPI Dependency Resolver, Inner Exception: Required license is missing: Sitecore.xDB.Base ---&amp;gt; Sitecore.Nexus.Licensing.LicenseException: Required license is missing: Sitecore.xDB.Base
   at ?????????????????????????????????????????.(????????????????????????????????????????? , String )
   at Sitecore.XConnect.Configuration.Extensions.InitializeLicenseCheck(IServiceCollection collection, String licenseFileOrXml)
   at Sitecore.XConnect.Configuration.Extensions.UseXConnectServiceInitializationConfiguration(IServiceCollection collection, IConfiguration configuration, String[] configurationSectionNames, String initializationSectionName, Boolean validateConfiguration)
   at Sitecore.XConnect.Web.Host.WebApiConfig.ConfigureServices(HttpConfiguration config)
   --- End of inner exception stack trace ---
   at Sitecore.XConnect.Web.Host.WebApiConfig.ConfigureServices(HttpConfiguration config)
   at System.Web.Http.GlobalConfiguration.Configure(Action`1 configurationCallback)
   at Sitecore.XConnect.Web.Global.Application_Start(Object sender, EventArgs e)"
&lt;/pre&gt;
&lt;p&gt;And because the health service ends up receiving errors, the Traefik container will fail, and the &lt;code&gt;docker-compose up&lt;/code&gt; will return errors in the console too:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://blog.jermdavis.dev/img/2021/2021-09-failed.png" target="_blank"&gt;&lt;img alt="Failed Start" src="https://blog.jermdavis.dev/img/2021/2021-09-failed.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For Google's benefit, that set of messages is:&lt;/p&gt;
&lt;pre data-enlighter-theme="droide-text" data-enlighter-language="text" style="width:100%; overflow:scroll;"&gt;Creating network "sitecore-xp0_default" with the default driver
Creating sitecore-xp0_mssql_1 ... done
Creating sitecore-xp0_solr_1  ... done
Creating sitecore-xp0_id_1        ... done
Creating sitecore-xp0_solr-init_1 ... done
Creating sitecore-xp0_xconnect_1  ... done
Creating sitecore-xp0_cm_1        ... done

ERROR: for cortexprocessingworker  Container "5f077e60de91" is unhealthy.

ERROR: for xdbautomationworker  Container "5f077e60de91" is unhealthy.

ERROR: for xdbsearchworker  Container "5f077e60de91" is unhealthy.

ERROR: for traefik  Container "19caaac9dcea" is unhealthy.
ERROR: Encountered errors while bringing up the project.
&lt;/pre&gt;
&lt;p&gt;Now while someone used to reading logs will fairly quickly spot the underlying cause of the console errors there, one of the benefits of containers is supposed to be that it works easily for everyone in your team. Testers, managers or front-end devs are less likely to understand the business of running containers, and given the "sometimes Docker just doesn't work" issues that we've all encountered (&lt;a href="https://sitecore.stackexchange.com/a/28676/233" rel="noopener" target="_blank"&gt;looking at you AppCmd errors on v10.0&lt;/a&gt;) it's not always obvious to the less hard-core technical amongst us when the issue is "license" and when it's "you didn't apply the right Windows Update and now &lt;a href="https://i.pinimg.com/originals/b2/b4/9a/b2b49a89501c1c7c4fbdfa00966f47b2.gif" rel="noopener" target="_blank"&gt;Docker is UNHAPPY&lt;/a&gt;".&lt;/p&gt;
&lt;h2&gt;A helpful addition&lt;/h2&gt;
&lt;p&gt;So after my team crashed into this issue of not realising that license expiry was the problem they were seeing, I wondered if I could help with future problems by making my project's "up" script check if the license has expired before it tries to start any containers...&lt;/p&gt;
&lt;p&gt;This isn't too hard to do, it turns out. We know that the license you're using is encoded into the &lt;code&gt;.env&lt;/code&gt; file for your project. It's stored as a Base64-encoded GZip stream. (You can &lt;a href="https://github.com/Sitecore/docker-tools/blob/bf850cf7909624dc50c9e78b9a91c0a0593af89c/powershell/src/Public/ConvertTo-CompressedBase64String.ps1#L21" rel="noopener" target="_blank"&gt;look at how this is done by examining the source for the &lt;code&gt;SitecoreDockerTools&lt;/code&gt; module&lt;/a&gt; that the &lt;code&gt;init.ps1&lt;/code&gt; script installs) So to test this, we need some code which can decode the license XML from the environment file field, find the &lt;code&gt;&amp;lt;expiration/&amp;gt;&lt;/code&gt; element and check that date against the current date.&lt;/p&gt;
&lt;p&gt;A bit of Google and some quick hacking lead me to this function:&lt;/p&gt;
&lt;pre data-enlighter-language="powershell" style="width:100%; overflow:scroll;"&gt;function Validate-LicenseData
{
    Param (
        $EnvironmentFile = ".env",
        $EnvironmentKey = "SITECORE_LICENSE"
    )

    $file = Get-Content $EnvironmentFile -Encoding UTF8

    $key = $file | ForEach-Object {
        if($_ -imatch "^$EnvironmentKey=.*")
        {
            return $_.SubString($EnvironmentKey.Length + 1)
        }
    }
    
    $data = [System.Convert]::FromBase64String($key)

    $memory = [System.IO.MemoryStream]::new()
    $memory.Write($data, 0, $data.Length)
    $memory.Flush()   
    $memory.Seek(0, [System.IO.SeekOrigin]::Begin) | Out-Null

    $gzip = [System.IO.Compression.GZipStream]::new($memory, [System.IO.Compression.CompressionMode]::Decompress)
    
    $s = [System.IO.StreamReader]::new($gzip);
    $xml = $s.ReadToEnd()   

    $s.Dispose();
    $gzip.Dispose()
    $memory.Dispose();

    $xml -match '&amp;lt;expiration&amp;gt;(.*?)&amp;lt;/expiration&amp;gt;' | Out-Null
    $textExpiry = $Matches[1]

    $expiry = [System.DateTime]::ParseExact($textExpiry, "yyyyMMddThhmmss", [System.Globalization.CultureInfo]::InvariantCulture)

    if($expiry -lt [System.DateTime]::Now)
    {
        throw "Your Sitecore license has expired."
    }
    else
    {
        $daysLeft = [int]($expiry - [System.DateTime]::Now).TotalDays
        Write-Host "You have $daysLeft days left on your license." -ForegroundColor Green
    }
}
&lt;/pre&gt;
&lt;p&gt;(I'm sure I can make this code better with some more thought – but it's a start)&lt;/p&gt;
&lt;p&gt;It will decode the license, extract the expiry date and then check it. If the license is expired it will throw (which should stop a script). I've wired that up in the &lt;code&gt;up.ps1&lt;/code&gt; script in the project, so it checks the license before it kicks off the process of starting containers. Missing out the function above, it's something like:&lt;/p&gt;
&lt;pre data-enlighter-highlight="10" data-enlighter-language="powershell" style="width:100%; overflow:scroll;"&gt;Param(
    [switch]$build = $false,
    [switch]$attach = $false
)

try
{
	pushd ".\docker"

	Validate-LicenseData

	$buildFlag = ""
	if($build)
	{
		$buildFlag = "--build"
	}

	Write-Host "Starting: XP=$xp, Build=$build, Attach=$attach"

	$detachFlag = "--detach"
	if($attach)
	{
		$detachFlag = ""
	}

	docker-compose up $buildFlag $detachFlag
}
finally
{
	popd
}
&lt;/pre&gt;
&lt;p&gt;(The &lt;a href="https://gist.github.com/jermdavis/25655ee9c095d20d15caf42fa3d27ded" rel="noopener" target="_blank"&gt;full code is available as a gist&lt;/a&gt; if you want to make something of your own from it)&lt;/p&gt;
&lt;p&gt;So the result of that for an expired license is an error:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://blog.jermdavis.dev/img/2021/2021-09-badlicense.png" target="_blank"&gt;&lt;img alt="Bad License" src="https://blog.jermdavis.dev/img/2021/2021-09-badlicense.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And if the license is valid it will report how many days left you have, before carrying on with the normal startup:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://blog.jermdavis.dev/img/2021/2021-09-goodlicense-1.png" target="_blank"&gt;&lt;img alt="Good License" src="https://blog.jermdavis.dev/img/2021/2021-09-goodlicense-1.png"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hopefully that means in the future my developers will know right away if they've hit a license expiry situation, and they can update their &lt;code&gt;.env&lt;/code&gt; file...&lt;/p&gt;
</content:encoded>
			<comments xmlns="http://purl.org/rss/1.0/modules/slash/">0</comments>
		</item>
	</channel>
</rss>